{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ee5485",
   "metadata": {},
   "source": [
    "#### **Hypothetical Document Embeddings HyDE in Document Retrieval**\n",
    "\n",
    "In this we expand the query into a Hypothetical document using LLM in which answer to that query can be present. \n",
    "\n",
    "And then we use this Hypothetical document as our search query that retrieves most semantic document to it.\n",
    "\n",
    "Advantages : \n",
    "- **Improved Relevance:** By expanding queries into full documents, HyDE can potentially capture more nuanced and relevant matches.\n",
    "- **Potential for Better Context Understanding:** The expanded query might better capture the context and intent behind the original question.\n",
    "- **Handle complex queries :** Useful for complex queries that might be difficult to match directly\n",
    "\n",
    "---\n",
    "\n",
    "LLM used - Ollama3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0374f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umesh/Desktop/RAG-in-detail/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a language model, so I don't have emotions or feelings like humans do. However, I'm functioning properly and ready to help with any questions or tasks you may have! How can I assist you today?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-12-08T16:38:06.765709Z', 'done': True, 'done_reason': 'stop', 'total_duration': 21131627167, 'load_duration': 3708394875, 'prompt_eval_count': 30, 'prompt_eval_duration': 12692674375, 'eval_count': 46, 'eval_duration': 3256736958, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--43eaa1f0-13e4-4d40-88e0-3295eaf1b6ee-0', usage_metadata={'input_tokens': 30, 'output_tokens': 46, 'total_tokens': 76})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama \n",
    "\n",
    "llm = ChatOllama(\n",
    "    model='llama3.2',\n",
    "    temperature=0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "llm.invoke(\"Hey How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37313abf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Embedding Model**\n",
    "\n",
    "We are using Sentence Transformers HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77ec91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of embeddings : 384\n",
      "[-0.0383385606110096, 0.1234646886587143, -0.02864295430481434, 0.05365273356437683, 0.0088453618809...\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model='all-MiniLM-L6-v2')\n",
    "\n",
    "text = \"This is a test document.\"\n",
    "query_result = embedding_model.embed_query(text)\n",
    "\n",
    "# show only the first 100 characters of the stringified vector\n",
    "print(f\"Dimension of embeddings : {len(query_result)}\")\n",
    "print(str(query_result)[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4bf54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### **Step1 - Load document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08432f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Pages : 33\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"../data/Understanding_Climate_Change.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "pages = loader.load()\n",
    "print(f\"Number of Pages : {len(pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822433e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 : \n",
      " Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an exte\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "print(f\"Page 1 : \\n {pages[0].page_content[:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e1042",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "##### **Step2 - Creating Chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7fa6129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks : 215\n",
      "Chunk 1 : \n",
      " page_content='Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past century, human' metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-07-13T20:17:34+03:00', 'author': 'Nir', 'moddate': '2024-07-13T20:17:34+03:00', 'source': '../data/Understanding_Climate_Change.pdf', 'total_pages': 33, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "\n",
    "chunks = text_splitter.split_documents(documents=pages)\n",
    "print(f\"Number of Chunks : {len(chunks)}\")\n",
    "print(f\"Chunk 1 : \\n {chunks[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d87cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### **Create a Vectorstore and retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000f26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use Chroma for this \n",
    "from langchain_chroma import Chroma \n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name='reliable-rag',\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory='../data/persistent_vectordb/HyDE'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72cd1ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to store 215 chunks : 5.89 seconds\n"
     ]
    }
   ],
   "source": [
    "# adding chunks to our DB\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "vector_store.add_documents(documents=chunks)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken to store {len(chunks)} chunks : {end-start :.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0966a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a retriever \n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ab4bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 1 \n",
      " Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past century, human\n",
      "-----------------------------------------------------------------------------------------\n",
      "Doc 2 \n",
      " The Arctic is warming at more than twice the global average rate, leading to significant ice \n",
      "loss. Antarctic ice sheets are also losing mass, contributing to sea level rise. This melting \n",
      "affects global ocean currents and weather patterns. \n",
      "Glacial Retreat \n",
      "Glaciers around the world are retreating, affecting water supplies for millions of people.\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## testing retriever on sample query\n",
    "query = \"What is global warming?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Doc {i+1} \\n {doc.page_content}\")\n",
    "    print(\"-\"*89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a56b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
