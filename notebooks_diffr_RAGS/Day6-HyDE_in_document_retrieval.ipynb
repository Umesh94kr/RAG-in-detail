{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ee5485",
   "metadata": {},
   "source": [
    "#### **Hypothetical Document Embeddings HyDE in Document Retrieval**\n",
    "\n",
    "In this we expand the query into a Hypothetical document using LLM in which answer to that query can be present. \n",
    "\n",
    "And then we use this Hypothetical document as our search query that retrieves most semantic document to it.\n",
    "\n",
    "Advantages : \n",
    "- **Improved Relevance:** By expanding queries into full documents, HyDE can potentially capture more nuanced and relevant matches.\n",
    "- **Potential for Better Context Understanding:** The expanded query might better capture the context and intent behind the original question.\n",
    "- **Handle complex queries :** Useful for complex queries that might be difficult to match directly\n",
    "\n",
    "---\n",
    "\n",
    "LLM used - Ollama3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0374f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umesh/Desktop/RAG-in-detail/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a language model, so I don't have emotions or feelings like humans do. However, I'm functioning properly and ready to help with any questions or tasks you may have! How can I assist you today?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-12-08T16:38:06.765709Z', 'done': True, 'done_reason': 'stop', 'total_duration': 21131627167, 'load_duration': 3708394875, 'prompt_eval_count': 30, 'prompt_eval_duration': 12692674375, 'eval_count': 46, 'eval_duration': 3256736958, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--43eaa1f0-13e4-4d40-88e0-3295eaf1b6ee-0', usage_metadata={'input_tokens': 30, 'output_tokens': 46, 'total_tokens': 76})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama \n",
    "\n",
    "llm = ChatOllama(\n",
    "    model='llama3.2',\n",
    "    temperature=0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "llm.invoke(\"Hey How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37313abf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Embedding Model**\n",
    "\n",
    "We are using Sentence Transformers HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77ec91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of embeddings : 384\n",
      "[-0.0383385606110096, 0.1234646886587143, -0.02864295430481434, 0.05365273356437683, 0.0088453618809...\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model='all-MiniLM-L6-v2')\n",
    "\n",
    "text = \"This is a test document.\"\n",
    "query_result = embedding_model.embed_query(text)\n",
    "\n",
    "# show only the first 100 characters of the stringified vector\n",
    "print(f\"Dimension of embeddings : {len(query_result)}\")\n",
    "print(str(query_result)[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4bf54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### **Step1 - Load document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08432f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Pages : 33\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"../data/Understanding_Climate_Change.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "pages = loader.load()\n",
    "print(f\"Number of Pages : {len(pages)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "822433e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 : \n",
      " Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an exte\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "print(f\"Page 1 : \\n {pages[0].page_content[:300]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e1042",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "##### **Step2 - Creating Chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7fa6129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks : 215\n",
      "Chunk 1 : \n",
      " page_content='Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past century, human' metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2024-07-13T20:17:34+03:00', 'author': 'Nir', 'moddate': '2024-07-13T20:17:34+03:00', 'source': '../data/Understanding_Climate_Change.pdf', 'total_pages': 33, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "\n",
    "chunks = text_splitter.split_documents(documents=pages)\n",
    "print(f\"Number of Chunks : {len(chunks)}\")\n",
    "print(f\"Chunk 1 : \\n {chunks[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d87cb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### **Create a Vectorstore and retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000f26ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use Chroma for this \n",
    "from langchain_chroma import Chroma \n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name='reliable-rag',\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory='../data/persistent_vectordb/HyDE'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72cd1ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to store 215 chunks : 5.89 seconds\n"
     ]
    }
   ],
   "source": [
    "# adding chunks to our DB\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "vector_store.add_documents(documents=chunks)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time taken to store {len(chunks)} chunks : {end-start :.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0966a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a retriever \n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69ab4bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 1 \n",
      " Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human\n",
      "-----------------------------------------------------------------------------------------\n",
      "Doc 2 \n",
      " and infrastructure. Cities are particularly vulnerable due to the \"urban heat island\" effect. \n",
      "Heatwaves can lead to heat-related illnesses and exacerbate existing health conditions. \n",
      "Changing Seasons \n",
      "Climate change is altering the timing and length of seasons, affecting ecosystems and human \n",
      "activities. For example, spring is arriving earlier, and winters are becoming shorter and\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## testing retriever on sample query\n",
    "query = \"What is the main cause of climate change?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Doc {i+1} \\n {doc.page_content}\")\n",
    "    print(\"-\"*89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965fec7e",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "##### **Creating LLM chain to get Hypothetical Document Embeddings**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865a56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Model \n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated\n",
    "from langchain_core.prompts import PromptTemplate \n",
    "\n",
    "class HyDE_document(BaseModel):\n",
    "    \"\"\"\n",
    "    It will return a Hypothetical Document in which answer to the query can be found. \n",
    "    \"\"\"\n",
    "    hyde_doc: Annotated[str, Field(description=\"It will return a Hypothetical Document\")]\n",
    "\n",
    "# configure llm with output structure \n",
    "llm_hyde_generation = llm.with_structured_output(HyDE_document)\n",
    "\n",
    "# prompt template for HyDE generation - input variables to be {query} and {chunk_size} \n",
    "template_hyde = \"\"\" \n",
    "Given the question '{query}', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
    "            the document size has be exactly {chunk_size} characters.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template_for_hyde = PromptTemplate(\n",
    "    template=template_hyde,\n",
    "    input_variables=['query', 'chunk_size']\n",
    ")\n",
    "\n",
    "## chain to generate Hypothetical Document\n",
    "chain_for_hyde_gen = prompt_template_for_hyde | llm_hyde_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cddda695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothetical Document : \n",
      " Climate Change: Main Cause\n",
      "\n",
      "The primary driver of climate change is human activities releasing greenhouse gases (GHGs) into the atmosphere, primarily carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O). These GHGs trap heat, leading to global warming.\n",
      "\n",
      "Causes:\n",
      "1. Burning fossil fuels (coal, oil, gas)\n",
      "2. Deforestation and land-use changes\n",
      "3. Agriculture and livestock production\n",
      "4. Industrial processes and transportation\n",
      "\n",
      "Effects: Rising temperatures, sea-level rise, extreme weather events, and altered ecosystems.\n"
     ]
    }
   ],
   "source": [
    "# lets test this out our chunk_size is 400\n",
    "query = \"What is the main cause of climate change?\"\n",
    "hypothetical_doc = chain_for_hyde_gen.invoke({'query' : query, 'chunk_size' : 400})\n",
    "\n",
    "print(f\"Hypothetical Document : \\n {hypothetical_doc.hyde_doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f5081bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc : 1\n",
      "Content : Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human\n",
      "-----------------------------------------------------------------------------------------\n",
      "Doc : 2\n",
      "Content : Costs of Inaction \n",
      "Economic Impacts of Climate Change \n",
      "The economic costs of climate change include damage to infrastructure, reduced agricultural \n",
      "productivity, health care costs, and lost labor productivity. Extreme weather events, such as \n",
      "hurricanes and floods, can cause significant economic disruption. Investing in climate action \n",
      "now can prevent much higher costs in the future.\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Now we'll use this hypothetical doc instead of query during retrieval\n",
    "retrieved_docs = retriever.invoke(hypothetical_doc.hyde_doc)\n",
    "\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Doc : {i+1}\")\n",
    "    print(f\"Content : {doc.page_content}\")\n",
    "    print(\"-\"*89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6acff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
