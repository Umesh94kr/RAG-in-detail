{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48fd46e5",
   "metadata": {},
   "source": [
    "#### **Re-ranking methods in RAG**\n",
    "\n",
    "##### **Overview** \n",
    "\n",
    "- Reranking is a crucial step in Retrieval-Augmented Generation (RAG) systems that aims to improve the relevance and quality of retrieved documents.\n",
    "\n",
    "- It involves reassessing and reordering initially retrieved documents to ensure that the most pertinent information is prioritized for subsequent processing or presentation.\n",
    "\n",
    "#### **Motivation** \n",
    "\n",
    "- The primary motivation for reranking in RAG systems is to overcome limitations of initial retrieval methods, which often rely on simpler similarity metrics\n",
    "\n",
    "- Reranking allows for more sophisticated relevance assessment, taking into account nuanced relationships between queries and documents that might be missed by traditional retrieval techniques.\n",
    "\n",
    "- This process aims to enhance the overall performance of RAG systems by ensuring that the most relevant information is used in the generation phase.\n",
    "\n",
    "#### **Key Components** \n",
    "\n",
    "Reranking systems typically include the following components:\n",
    "\n",
    "1) Initial Retriever : Often a vector store using embedding-based similarity search.\n",
    "\n",
    "2) Reranking Model : \n",
    "    - A Large Language Model (LLM) for scoring relevance\n",
    "    - A Cross-Encoder model specifically trained for relevance assessment \n",
    "\n",
    "3) Scoring Mechanism: A method to assign relevance scores to documents\n",
    "\n",
    "4) Sorting and Selection Logic: To reorder documents based on new scores\n",
    "\n",
    "#### **Benefits of this Approach** \n",
    "\n",
    "- Improved Relevance: By using more sophisticated models, reranking can capture subtle relevance factors.\n",
    "\n",
    "- Flexibility: Different reranking methods can be applied based on specific needs and resources.\n",
    "\n",
    "- Enhanced Context Quality: Providing more relevant documents to the RAG system improves the quality of generated responses.\n",
    "\n",
    "- Reduced Noise: Reranking helps filter out less relevant information, focusing on the most pertinent content.\n",
    "\n",
    "#### **Conclusion** \n",
    "\n",
    "- Reranking is a powerful technique in RAG systems that significantly enhances the quality of retrieved information. \n",
    "\n",
    "- Whether using LLM-based scoring or specialized Cross-Encoder models, reranking allows for more nuanced and accurate assessment of document relevance.\n",
    "\n",
    "- This improved relevance translates directly to better performance in downstream tasks, making reranking an essential component in advanced RAG implementations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **LLM used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a5c8cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I\\'m just a language model, I don\\'t have personal experiences or emotions like humans do. However, I am currently:\\n\\n1. Processing your question and preparing to respond.\\n2. Running on computer servers, responding to queries from users like you.\\n3. Continuously learning and improving my knowledge base through machine learning algorithms.\\n\\nI\\'m always \"on\" and ready to help with any questions or topics you\\'d like to discuss! What about you? What are you doing right now?', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-12-25T15:16:15.715686Z', 'done': True, 'done_reason': 'stop', 'total_duration': 23676567541, 'load_duration': 1218095333, 'prompt_eval_count': 32, 'prompt_eval_duration': 15533685625, 'eval_count': 98, 'eval_duration': 6921936541, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019b5614-a438-7fc2-b85d-be2d0456d34c-0', usage_metadata={'input_tokens': 32, 'output_tokens': 98, 'total_tokens': 130})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama \n",
    "\n",
    "llm = ChatOllama(\n",
    "    model='llama3.2',\n",
    "    temperature=0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "llm.invoke(\"Hey What are you doing right now\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f5832b",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "#### **Embedding model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "789ad49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text embedding : 24\n",
      "Time taken to convert text to embedding : 0.12 sec\n",
      "[-0.0383385606110096, 0.1234646886587143, -0.02864295430481434, 0.05365273356437683, 0.0088453618809...\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import time \n",
    "\n",
    "# this is all-MiniLM-L6-v2 model \n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "text = \"This is a test document.\"\n",
    "\n",
    "start = time.time()\n",
    "query_result = embedding_model.embed_query(text)\n",
    "total_time = time.time() - start\n",
    "# show only the first 100 characters of the stringified vector\n",
    "print(f\"Length of text embedding : {len(text)}\")\n",
    "print(f\"Time taken to convert text to embedding : {total_time :.2f} sec\")\n",
    "print(str(query_result)[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37473c11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Load the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78f9b30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs : 33\n",
      "Average count of words in a doc : 280\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader \n",
    "\n",
    "file_path = '../data/Understanding_Climate_Change.pdf'\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Number of docs : {len(docs)}\")\n",
    "\n",
    "avg_doc_words = 0\n",
    "\n",
    "for doc in docs:\n",
    "    total_words_in_doc = len(doc.page_content.split(' '))\n",
    "    avg_doc_words += total_words_in_doc\n",
    "\n",
    "print(f\"Average count of words in a doc : {round(avg_doc_words/len(docs))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4107ba9",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "#### Creating Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0cf7da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks : 215\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Total number of chunks : {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83080e1",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "#### **Creating Vcetorstore and retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4eb213d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f1b1f535-9e42-4bd6-aafe-d809c0619f62',\n",
       " '69b45fba-0a4c-494f-bb26-fc84d70aa0eb',\n",
       " 'bf64dec9-a6c0-43a2-8613-92ca6c9a5077',\n",
       " '08a4a5af-6aad-4185-beb8-543c62bdc6d3',\n",
       " '6f5cd744-8cfb-4829-a1dd-7c74ab5d09fa',\n",
       " '8e7372fa-9222-477f-975b-a65ea687448a',\n",
       " '6e532d39-f85a-40bb-acb0-ec39dccf6482',\n",
       " '2ae80f52-ddbb-4f6e-8e02-ea055aefd6dc',\n",
       " 'd658f334-8c6c-40f4-9b12-19941954bfe4',\n",
       " '779b3bbe-31e6-4210-b090-07cad85e142a',\n",
       " 'adb106a3-4beb-424b-901f-5fc1ead6372d',\n",
       " 'f6dc73cc-e5d6-458f-a4b4-ea654c1913b9',\n",
       " '0c788f6b-2c04-44cf-bbaf-e802b4527719',\n",
       " '97f8f9de-e9a8-4ef5-a17e-c29d01d4e980',\n",
       " '1e08b214-c9a5-4881-b44a-ce1eb70229fc',\n",
       " 'd27147f0-bbbd-406c-8bb7-708be0851dad',\n",
       " '47762291-d8d6-45c6-9483-0c6e7991e63a',\n",
       " '02be4837-936e-4300-b7f4-d72a478af01b',\n",
       " '1ee63439-cb9a-4f6a-91b1-98e154f6a227',\n",
       " 'f614f4f7-ea7e-43b8-87ed-ff187e568653',\n",
       " '6c1a9f2e-0dfd-42c7-ab4c-c981655d8de1',\n",
       " '5d32612f-a304-4199-8965-5f4d4d988d76',\n",
       " '66deb4c6-0725-4995-b73e-7354022f2bee',\n",
       " '7836ec97-9949-47bb-a7df-4c7af09f11ab',\n",
       " 'e3845b00-9be7-4322-a71e-80a45903cde8',\n",
       " '84a8afad-1275-499c-bd4d-b942d392070a',\n",
       " '54b47a32-7bec-4e0b-9f71-445c99a0f4f9',\n",
       " '1879a699-a5bb-48df-a7e1-3144f9435362',\n",
       " '90e1debc-e991-4fb1-9011-6ff7f8f479a8',\n",
       " '9999c3c8-11e9-4e89-9693-89e9fa271321',\n",
       " '4cc6e125-bb2d-4d5e-967c-ea9b37c6d9a6',\n",
       " 'fc9e93ff-4cd5-4db9-9f30-f790023f099b',\n",
       " '7719ed8d-ac6f-4498-a870-ec0cd7a83460',\n",
       " '82a9bd44-0af5-4252-9d7f-c2c88fda3b97',\n",
       " '75d457ae-1132-4dd7-9406-724496e8d779',\n",
       " '0b980acc-ae0f-4e5e-9116-a3884d946a2d',\n",
       " 'e2c8d11d-18d4-45dd-99ee-41a385f9c8eb',\n",
       " 'f3bf2d2b-ae5d-4d88-ab5e-5dbb3a71f7c1',\n",
       " 'd7563841-35ba-45cc-b7a2-eb35d39f5658',\n",
       " '08fbe939-a57c-4134-bdae-cbd593c07459',\n",
       " 'b31544b0-2abf-4804-ab51-3eb9284b2004',\n",
       " 'dc15d982-e5f8-4af0-9500-8c90c2fdf18e',\n",
       " 'a9133608-dbc8-4804-9aa9-b7e611c881f8',\n",
       " '2bca14c2-07b4-4b57-821e-d29b3d7ea588',\n",
       " '028434a1-9b81-4d0f-a1a8-392f1070ff44',\n",
       " '7f748ebb-6bd3-4ace-8e6c-b127fd597dd3',\n",
       " 'e6571e16-5e3f-4491-b497-201ef612b31f',\n",
       " '8645bc0b-f145-43f3-9098-fb12ef659711',\n",
       " 'db5e8db2-9d82-42c0-870c-aa841fc987eb',\n",
       " 'b0f92f9f-2e6e-4522-9eb0-1cc5db4d0239',\n",
       " 'eb2be51e-ba00-4f37-8329-93eb04b1257f',\n",
       " '588b42d4-dc0e-4d66-bc18-28930f093619',\n",
       " '2c446f0f-9540-4049-a6da-ec4dc9b8a3d2',\n",
       " '0286c71b-0018-4714-92a8-d516a6e52115',\n",
       " 'c62fbe07-988d-4b66-9a0a-702a8cd48ef2',\n",
       " '50497e4e-0f67-4e37-ad59-bb99f3cfb7ac',\n",
       " 'cc95d10e-d310-4a51-9302-87ba18adf06e',\n",
       " '2d3f1e5e-299d-4333-9fe3-d33d96daf9d4',\n",
       " 'd3ab9849-26d8-4ddf-bdf4-312054c06bc8',\n",
       " '89176b89-6d20-4178-80a6-3bd641a49293',\n",
       " 'fba44d62-0792-42ac-9a68-8e58ffe745bf',\n",
       " 'd98eb643-821c-4aee-a999-820af04ca1f6',\n",
       " '7cac8666-ee6d-4a7a-a2fc-b1d199990dd7',\n",
       " '143fea76-f0f7-4510-ae25-1050e54b20db',\n",
       " '944a8ca7-a0d4-485a-a32b-e37dab81f006',\n",
       " 'f1b0341a-e68d-42d5-a24f-e0b69d4a2c4d',\n",
       " '3d1a401c-67db-4121-924f-384f25c3c182',\n",
       " 'db4d5ca6-bec0-4646-9e78-94ac49a8d79f',\n",
       " '4e98c795-0389-49f6-a3bd-ff1a546f839c',\n",
       " '878786fe-0f6e-4a53-a3e3-392d29f27f7b',\n",
       " '4c396412-844b-4843-9234-6563ee8a8bc9',\n",
       " '6066272f-c63f-4afb-a100-1a09843d89f6',\n",
       " 'ddec1b10-14c9-4b13-bacd-4915d1e0a45c',\n",
       " '85fdf982-8540-47ee-9e9c-d972f56ea8f7',\n",
       " '36e7ebc7-4f6b-407a-9ce6-949d83fc7f42',\n",
       " 'de40dc54-fcea-4b6f-8140-6e5d104c8ae2',\n",
       " 'a0d190c5-2cd2-45fb-921b-4f5b4cbdf712',\n",
       " '5efd823e-76ec-41fc-a7d6-b3a37e4f527a',\n",
       " 'c95489c0-dc94-48f5-b3b7-9b759a4e8367',\n",
       " 'a1d5c5e1-fac2-4386-94dc-d1ca45bfd14f',\n",
       " 'aebcd3f7-e4b9-4506-8f0e-b6ceeb52820b',\n",
       " 'c6446e07-93bc-4da8-8ae4-88349e85b6e7',\n",
       " '37afd372-68d1-4765-9ff0-917073074bf2',\n",
       " '493d77f6-a9cf-459d-94c1-1a4adb3bfe96',\n",
       " '1928dea0-95c2-4493-9aeb-13a209f6f857',\n",
       " 'ca2577df-2382-4dda-8ec6-abc2e04b902d',\n",
       " 'ec83d8aa-f9b0-4465-920f-724c9b6f2b47',\n",
       " '572c5371-78c9-4ae3-9aff-5b25d17753ca',\n",
       " 'a49dc778-0838-4cc3-b127-1fa07b98ee4b',\n",
       " 'ab3fde34-931b-4580-87ac-2fe50bc1071f',\n",
       " '882d07ad-c2eb-4356-a485-d2570c86eafe',\n",
       " '1ca07e43-70dd-4d24-8a4b-70b9a420c660',\n",
       " '66c6fc1b-75d1-4bdb-a1fe-fa9fdc91ef09',\n",
       " '418dcbdf-a797-4a34-9110-8572f82a03ce',\n",
       " '4c5fc912-07a8-4064-b68f-312c6b615bef',\n",
       " 'e508c121-1b5a-4659-ae50-adf58527a40a',\n",
       " '9fac1632-9491-4943-9f81-66e2e286ace2',\n",
       " '6d585833-eb3f-437d-94ed-15bee76b366f',\n",
       " '61527be1-892f-4c2f-ad5c-a38c1f28e186',\n",
       " 'e7ea322f-6d3e-4bed-b3a3-2f6f7c4f0778',\n",
       " '05291130-8c69-4636-8ef4-0527fdc1b8f2',\n",
       " '815e48e3-5599-4813-8912-6a265996581e',\n",
       " '404e54f6-5d10-419b-9f7d-a91fb508c893',\n",
       " 'c8063774-27ce-4f2c-852a-b5c10ef070b0',\n",
       " 'c573dfee-ec94-4b7f-9579-bbddfee3c497',\n",
       " 'f67ee95c-127c-405b-90ff-d09bd74b6361',\n",
       " '8182ea98-6235-45cb-968c-388bdbf5fb52',\n",
       " '44845568-bf56-4608-a1f9-a1a331c71a19',\n",
       " 'ccb433df-72bf-439a-94e4-d8abc1563976',\n",
       " 'e5408655-441d-4b56-80d1-c761cb60da25',\n",
       " 'e994309a-fd6f-4da4-bc44-0178462483ee',\n",
       " '4f75ffd0-d275-4f83-b8c2-b1254250e215',\n",
       " '332ebedc-5de9-422b-8b0f-d85c91988b3e',\n",
       " 'e1a2e2ef-9284-4206-95b3-ea1e36d6dca6',\n",
       " '27efa48b-a011-47b6-b4da-f62ac32c0033',\n",
       " '72bebff6-8abe-48e1-9e10-c437fcedeb06',\n",
       " 'b390447b-2b15-4dd4-b90a-55adc0048d54',\n",
       " '9ef5a79f-989b-4c7d-b817-cfaca2252f25',\n",
       " '0945b94a-7516-414b-b5ef-58cb11b7529c',\n",
       " '80334fc3-622f-4241-b4cb-f568d1d61586',\n",
       " 'a8cb370f-fb36-40bb-8cfa-7cbfd0d7aa06',\n",
       " 'be20ee88-0c94-43c0-8244-8ffc5a2622de',\n",
       " 'd1b78de0-98fa-43e8-bce2-031181087102',\n",
       " '6b695239-09a3-4f7e-b1bc-7692ed089705',\n",
       " '9a77b3c3-2673-4e37-b4de-004a7178115c',\n",
       " 'd77aaf4d-65d7-4860-9edc-3df9fc3f9746',\n",
       " '632d27c9-3a7e-41a0-9781-513b92978080',\n",
       " '44021d95-2ba5-4c9f-9cb9-a30ce627122d',\n",
       " 'ea43f902-639e-4aad-8b77-2c5389a9202a',\n",
       " '58df7c39-382f-4f6a-88b3-1d9e058bc859',\n",
       " '6cf2787b-765f-4b57-81d1-17a4ea18811d',\n",
       " 'bc06f9b0-15c8-44d8-a060-6345a66b39d1',\n",
       " '7b5e86f3-b49f-41c2-babf-a4d0f5bfa686',\n",
       " '8e826f8b-7a51-45b5-8cbd-52e3bc1519cc',\n",
       " '9f1d3862-7801-4ad7-9c2e-e00a2dfb7ef1',\n",
       " 'e799fef2-8ade-4368-9b08-4c50a768ae3a',\n",
       " '60a3c709-017a-42e2-a587-fc597734bb01',\n",
       " 'baec1341-32c5-4621-ae24-53f3df84fa14',\n",
       " 'b4c2fe33-3fd8-463a-bbbc-3af666ea4dd0',\n",
       " '012ac930-bf11-4c50-99a0-0fed177719ed',\n",
       " '010bc2b4-3ea8-46a2-aa21-063ddbc1c15a',\n",
       " 'e75a0ae0-9ec1-4452-ad22-df8e5e193968',\n",
       " '73adfee0-5b69-44e8-97c5-8f67be21428b',\n",
       " '344b24c3-a44a-4f39-b43d-092bdf8d60c6',\n",
       " '153a4efe-3b3f-43d5-9b14-e92219697c43',\n",
       " '78502595-ebe3-4adc-a9ec-57c9c09fcf53',\n",
       " '93c63a0c-228c-4838-9329-18ca6ccc94c9',\n",
       " 'ba8d602f-132a-450f-b14a-39e002aaea38',\n",
       " '059d285d-be97-478f-a016-cd7aa3645777',\n",
       " 'fa2e3a79-fc84-4788-9aeb-c607227b6266',\n",
       " '70415e92-7e7c-4a20-8c40-05d3fbb5a284',\n",
       " '9a3f54bd-49c3-4595-9b53-d131be2fecc2',\n",
       " '08a43b15-1956-40fc-acae-22fa960e6e47',\n",
       " '08f25fbf-cc54-45ff-a248-808b5805cb2b',\n",
       " '2b7a03e6-8954-427a-aef5-d28509d96f55',\n",
       " '6d894050-28e4-4bd2-a3f1-378283de368d',\n",
       " '9718a9b0-f848-4d5c-9725-96b6d500087b',\n",
       " 'ce7cdcac-9d50-420a-b8fd-496d91897a49',\n",
       " '29a0d784-e614-424e-ae15-ea5a4e6648d7',\n",
       " 'e4c99160-300a-45d3-b96a-fcf79a83d614',\n",
       " '7adc7c66-23ea-4df3-bf3c-66c52a2b0f37',\n",
       " '2038250a-04db-4c99-a712-1a73c339a61e',\n",
       " '3dc670a4-db9d-4a0b-9e66-4b12e3390711',\n",
       " '122d07fd-eb74-46d7-b9f7-3fb36156126c',\n",
       " '4bc2ba85-0b67-4f3d-b031-747f115d8324',\n",
       " 'c36d433d-8d84-45ff-a67e-5e5f10d250a4',\n",
       " '74b44792-ed48-4fda-9c73-4e167b372afe',\n",
       " 'bd5e99dd-a2fc-4715-b63a-ae900fab9625',\n",
       " 'f98cbf99-f0ee-49ea-bb41-6e1ce61a4308',\n",
       " 'fdd89aae-3c44-4fa3-a831-82c10699153a',\n",
       " '7cfcbd8a-8fb3-433e-82e4-06e7de6ff136',\n",
       " 'c53832f1-1859-4612-8a85-9951ae961301',\n",
       " '0e0f9fff-9d66-4dd9-9390-58fc6a8165c5',\n",
       " '8cf12efd-82f5-4c5e-a8bf-4c63b9a26507',\n",
       " '798c3f9e-a3df-4f66-b6a2-72209655f516',\n",
       " 'c3d2dcd1-53c6-4018-b5da-016cae40d1b9',\n",
       " '49a363fe-6255-4f12-a3eb-a62aa31a4af2',\n",
       " '6e73e540-f2b4-4959-a437-fd50bac51328',\n",
       " '01050e07-d2e5-4011-8843-d7a680a3fc38',\n",
       " '5bd47687-55f2-4864-81e8-f6bc78b743db',\n",
       " 'c4d92858-0a13-4be1-8330-00b95054f956',\n",
       " '29410060-1344-410d-81f9-0a57e6857f35',\n",
       " '90cce30e-c0a1-42f8-b7ac-d2ab198946a6',\n",
       " '37fc1d1d-790a-47ea-90cc-468ce9f8a894',\n",
       " 'ead6ce53-85c0-4786-8427-36dd25d22688',\n",
       " '6ea5c30b-8917-4d5c-b30c-266ee352e9d9',\n",
       " '6f93c32a-6592-40e2-bd07-fbba8af8176f',\n",
       " 'feb8a0de-86ca-4ab0-bdc6-254660773aa1',\n",
       " '2e5d09df-d906-45f7-8b77-79c7150839fd',\n",
       " '5f7acf5b-ff64-4cb6-abbf-d11fab1f0f12',\n",
       " '63dcd2b9-1db0-4ed9-b9c4-6c8262072873',\n",
       " '54b08669-f72e-4520-ba8f-1e56b3e910dc',\n",
       " '64cec0b4-0c5d-40ef-88fc-a6dc7eb98527',\n",
       " '75a3ec1d-c646-4e5d-a217-f931292e4ecb',\n",
       " 'f770f44a-9fbd-457e-ad1e-3e08e455c593',\n",
       " 'fa6e4399-764c-4a54-978b-3ae637179888',\n",
       " '2403bb06-134a-46eb-9935-7e302ffbc22f',\n",
       " '9749661c-e0e7-4975-8e27-7b2642fc910c',\n",
       " '38dbc1c5-92f6-44e6-bd57-0ca23ad23852',\n",
       " '7609ebb4-555f-4b21-8d29-12147610411c',\n",
       " '2e0bee17-8eb2-41e5-b333-5ec84933cb9f',\n",
       " 'c27af550-de80-4d88-bea3-724022cf101f',\n",
       " 'ab224c52-cbd4-4ee1-af43-cee0c641432b',\n",
       " '86d075f2-1e85-42e4-8f8e-89b0e758d350',\n",
       " '88060a7a-c30e-4957-b0e0-cdd28c3e9ebf',\n",
       " '7381abef-04ce-4fee-930a-f1d0b00bce7b',\n",
       " '58399235-a081-43f0-98c3-1d9bfa234998',\n",
       " 'd9e8bcb9-a94a-4a93-898d-723375fea857',\n",
       " 'b305b11f-19c9-400b-ada5-212e4ac371b2',\n",
       " '1a0bd169-9484-4c15-9b7f-638216fe84c9',\n",
       " '74ccd051-e1af-4c2d-b8d1-ea2e3a6fefcd',\n",
       " '9360e09f-b7c1-4178-aacb-9b1d11f32470',\n",
       " 'f07fd41e-c89b-49ce-8f9d-fc3244987f34',\n",
       " 'ff212783-7684-4aff-9192-da415b4e8673',\n",
       " '7f24bdfa-301c-4923-b7ac-9d18ee9633ed']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embedding_model.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embedding_model,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "## adding chunks to the vectorstore \n",
    "vector_store.add_documents(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea67325c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "Understanding Climate Change \n",
      "Chapter 1: Introduction to Climate Change \n",
      "Climate change refers to significant, long-term changes in the global climate. The term \n",
      "\"global climate\" encompasses the planet's overall weather patterns, including temperature, \n",
      "precipitation, and wind patterns, over an extended period. Over the past century, human\n",
      "=========================================================================================\n",
      "Chapter 14: Climate Change and the Economy \n",
      "Economic Transformation\n",
      "=========================================================================================\n",
      "and infrastructure. Cities are particularly vulnerable due to the \"urban heat island\" effect. \n",
      "Heatwaves can lead to heat-related illnesses and exacerbate existing health conditions. \n",
      "Changing Seasons \n",
      "Climate change is altering the timing and length of seasons, affecting ecosystems and human \n",
      "activities. For example, spring is arriving earlier, and winters are becoming shorter and\n",
      "=========================================================================================\n",
      "of biodiversity and disrupt ecological balance. \n",
      "Marine Ecosystems \n",
      "Marine ecosystems are highly vulnerable to climate change. Rising sea temperatures, ocean \n",
      "acidification, and changing currents affect marine biodiversity, from coral reefs to deep-sea \n",
      "habitats. Species migration and changes in reproductive cycles can disrupt marine food webs \n",
      "and fisheries.\n",
      "=========================================================================================\n",
      "Mitigation involves reducing or preventing the emission of greenhouse gases, while \n",
      "adaptation involves making adjustments to social, economic, and environmental practices to \n",
      "minimize the damage caused by climate change. \n",
      "Renewable Energy \n",
      "Transitioning to renewable energy sources, such as wind, solar, and hydroelectric power, is\n"
     ]
    }
   ],
   "source": [
    "# adding a retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# try the retriever \n",
    "relevant_docs = retriever.invoke(\"What is Climate Change?\")\n",
    "\n",
    "for doc in relevant_docs:\n",
    "    print(\"=\"*89)\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f517aa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Two types of Reranking**\n",
    "\n",
    "- **LLM based**\n",
    "    - For this we only use LLM with a scoring prompt for query and document\n",
    "    - Based on those assigned score we sort the docs\n",
    "    - And retrieves top-k docs\n",
    "\n",
    "    - Cons : \n",
    "        - Expensive üí∞\n",
    "        - Slow ‚è≥\n",
    "        - Hard to scale (O(K) LLM calls)\n",
    "\n",
    "- **CrossEncoder reranker**\n",
    "    - A neural model trained explicitly for reranking that encodes query and document together.\n",
    "    - Pros\n",
    "        - Much faster than general LLMs\n",
    "        - Cheaper\n",
    "        - Very strong ranking accuracy\n",
    "        - Deterministic scores\n",
    "    - Cons\n",
    "        - Still O(K) forward passes\n",
    "        - Less flexible than promptable LLMs\n",
    "        - Limited context window\n",
    "\n",
    "---\n",
    "\n",
    "**LLM Based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0feb74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated \n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Data Validation\n",
    "class RerankerDataModel(BaseModel):\n",
    "    \"\"\" \n",
    "    Assigns a score on scale of 0 to 10 for the relevance of query to document.\n",
    "    \"\"\"\n",
    "    score: Annotated[int, Field(description=\"a score on scale of 0 to 10 for the relevance of query to document\")]\n",
    "\n",
    "# configuring LLM eith structured output \n",
    "scoring_llm = llm.with_structured_output(RerankerDataModel)\n",
    "\n",
    "# prompt template for scoring \n",
    "scoring_template_content = \"\"\"\n",
    "    You are a good evaluator. \n",
    "    You are provided with a query : {query}\n",
    "    and a document : {doc}.\n",
    "\n",
    "    You need to give a score on 0 to 10.\n",
    "\"\"\"\n",
    "\n",
    "scoring_template = PromptTemplate(\n",
    "    template=scoring_template_content,\n",
    "    input_variables=['query', 'doc']\n",
    ")\n",
    "\n",
    "scoring_chain = scoring_template | scoring_llm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f27e1880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc : Understanding Climate Change \n",
      "Chapter 1: Introduct\n",
      "Score : 8\n",
      "=========================================================================================\n",
      "Doc : Chapter 14: Climate Change and the Economy \n",
      "Econom\n",
      "Score : 8\n",
      "=========================================================================================\n",
      "Doc : and infrastructure. Cities are particularly vulner\n",
      "Score : 6\n",
      "=========================================================================================\n",
      "Doc : of biodiversity and disrupt ecological balance. \n",
      "M\n",
      "Score : 6\n",
      "=========================================================================================\n",
      "Doc : Mitigation involves reducing or preventing the emi\n",
      "Score : 6\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# lets try to score the LLM results \n",
    "query = \"What is Climate Change?\"\n",
    "\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "docs_scores = []\n",
    "for doc in retrieved_docs:\n",
    "    score_result = scoring_chain.invoke({'query' : query, 'doc' : doc.page_content})\n",
    "    doc_score = (doc.page_content, score_result.score)\n",
    "    docs_scores.append(doc_score)\n",
    "    print(f\"Doc : {doc.page_content[:50]}\")\n",
    "    print(f\"Score : {score_result.score}\")\n",
    "    print(\"=\"*89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "782923e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc : 1, Score : 8\n",
      "Doc : 2, Score : 8\n",
      "Doc : 3, Score : 6\n",
      "Doc : 4, Score : 6\n",
      "Doc : 5, Score : 6\n"
     ]
    }
   ],
   "source": [
    "## rerank the docs \n",
    "rerank_docs = sorted(docs_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, doc in enumerate(rerank_docs):\n",
    "    print(f\"Doc : {i+1}, Score : {doc[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5bd02",
   "metadata": {},
   "source": [
    "Now we can use top k documents from reranked documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f544ff",
   "metadata": {},
   "source": [
    "#### **Custom Retriever which contains Reranking logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00e39b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRetriever:\n",
    "    def __init__(self, retriever, top_k=1):\n",
    "        self.retriever = retriever \n",
    "        self.top_k = top_k\n",
    "\n",
    "    def _get_retrieved_docs(self, query):\n",
    "        retrieved_docs = self.retriever.invoke(query)\n",
    "        return retrieved_docs \n",
    "    \n",
    "    def _get_relevancy_score(self, query, docs):\n",
    "        score_docs = []\n",
    "        for doc in docs:\n",
    "            score_result = scoring_chain.invoke({'query' : query, 'doc' : doc.page_content})\n",
    "            doc_score = (doc.page_content, score_result.score)\n",
    "            score_docs.append(doc_score)\n",
    "        \n",
    "        return score_docs \n",
    "    \n",
    "    def _get_reranked_docs(self, score_docs):\n",
    "        reranked_docs = sorted(score_docs, key=lambda x: x[1], reverse=True)\n",
    "        return reranked_docs[:self.top_k]\n",
    "    \n",
    "    def main(self, query):\n",
    "        retrieved_docs = self._get_retrieved_docs(query)\n",
    "        score_docs = self._get_relevancy_score(query, retrieved_docs)\n",
    "        reranked_docs = self._get_reranked_docs(score_docs)\n",
    "        \n",
    "        return reranked_docs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5a135c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self, llm, custom_retriever):\n",
    "        self.llm = llm\n",
    "        self.retriever = custom_retriever\n",
    "\n",
    "    def get_template(self):\n",
    "        template_text = \"\"\" \n",
    "                        You are a helpful assistant that helps user to get answers of query they asked {query}, from the provided context {context}.\n",
    "                        \"\"\"\n",
    "        prompt_template = PromptTemplate(\n",
    "            template=template_text,\n",
    "            input_variables=['query', 'context']\n",
    "        )\n",
    "\n",
    "        return prompt_template\n",
    "    \n",
    "    def rag_chain(self, query, context):\n",
    "        prompt = self.get_template()\n",
    "\n",
    "        chain = prompt | self.llm \n",
    "        response = chain.invoke({'query' : query, 'context' : context})\n",
    "        return response\n",
    "\n",
    "    def main(self, query):\n",
    "        retrieved_docs = self.retriever.main(query)\n",
    "        \n",
    "        context = \"\"\n",
    "        for doc in retrieved_docs:\n",
    "            context += doc[0]\n",
    "            context += \"/n\"\n",
    "        \n",
    "        response = self.rag_chain(query, context)\n",
    "        return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6849eded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : What is Climate Chage?\n",
      "=========================================================================================\n",
      "Response : I'd be happy to help you understand Climate Change.\n",
      "\n",
      "So, according to the provided context, Climate Change refers to significant, long-term changes in the global climate. This includes changes in:\n",
      "\n",
      "1. Temperature\n",
      "2. Precipitation (amount of rainfall or snowfall)\n",
      "3. Wind patterns\n",
      "\n",
      "These changes occur over an extended period, and they are considered \"significant\" because they have a substantial impact on our planet's weather patterns.\n",
      "\n",
      "In simple terms, Climate Change is about the long-term shifts in the Earth's climate system, which can be caused by human activities and natural factors.\n",
      "\n",
      "Would you like to know more about the causes of Climate Change or its effects?\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    custom_retriever = CustomRetriever(retriever, top_k=2)\n",
    "    rag = RAG(llm, custom_retriever)\n",
    "    query = input(\"Write your query : \")\n",
    "    print(f\"Query : {query}\")\n",
    "    response = rag.main(query)\n",
    "    print(\"=\"*89)\n",
    "    print(f\"Response : {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4b3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
