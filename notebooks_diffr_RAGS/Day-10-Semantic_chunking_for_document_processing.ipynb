{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd74baf",
   "metadata": {},
   "source": [
    "#### **Semantic Chunking For Document Processing**\n",
    "\n",
    "While chunking we often define **chunk_size** and used to break the text (harsh logic).\n",
    "\n",
    "In semantic chunking we often break the text at more natural breakpoints, preserving the semantic context.\n",
    "\n",
    "#### **Algorithm Behind Langchain Semantic Chunker to make semantic chunks**\n",
    "\n",
    "You split the text into small parts (30-40 tokens) \n",
    "\n",
    "Now let say you have t1, t2, t3, t4\n",
    "\n",
    "we'll check semantic relation between each adjacent text, if their score is greater than some threshold then combine them else start a new chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238836a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **LLM used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3cd8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model='llama3.2',\n",
    "    temperature=0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "llm.invoke('How are you?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13db60",
   "metadata": {},
   "source": [
    "#### **Embedding Model used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977db394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umesh/Desktop/RAG-in-detail/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of sample embeddings : 384\n",
      "Sample embedding : [-0.013380538672208786, 0.003255972173064947, 0.10806030035018921, 0.08322358131408691, 0.02040085941553116, -0.049066152423620224, 0.0722508355975151, 0.002980925841256976, -0.08823534101247787, 0.016058299690485, -0.03367079421877861, -4.332493062975118e-06, -0.02510129101574421, 0.0007887802203185856, 0.060331884771585464, -0.0415474958717823, 0.07702311128377914, -0.14256997406482697, -0.13958506286144257, 0.06023767963051796, 0.003192346775904298, 0.018982844427227974, 0.02300790697336197, 0.06056844815611839, -0.07911035418510437, -0.05399537831544876, -0.0008475205395370722, 0.03202424943447113, -0.029674910008907318, -0.04484577104449272, -0.10411098599433899, 0.06399180740118027, -0.05713418126106262, -0.02695028856396675, -0.028776653110980988, 0.00333896791562438, -0.0355900302529335, -0.13525626063346863, 0.009469274431467056, 0.0003555373114068061, 0.009924577549099922, -0.0014938903041183949, -0.009747199714183807, -0.0021706046536564827, 0.06437141448259354, -0.04134561866521835, -0.015959464013576508, 0.07168345153331757, 0.09831950813531876, 0.010891384445130825, -0.10564935207366943, -0.06154218316078186, -0.04495823755860329, 0.03288338705897331, 0.06448811292648315, 0.026930589228868484, -0.022059716284275055, 0.008090948686003685, 0.0885234996676445, -0.040078986436128616, -0.011959749273955822, 0.025354033336043358, -0.10569483041763306, 0.0038036201149225235, 0.059116121381521225, -0.016421761363744736, -0.06289204210042953, -0.03538224473595619, -0.03384290635585785, -0.05755750089883804, -0.01964549534022808, -0.07316037267446518, 0.03075730986893177, -0.017475150525569916, 0.029496576637029648, -0.08609264343976974, 0.052657350897789, -0.04254796728491783, 0.03953508660197258, 0.04585482180118561, 0.06450486183166504, -0.06745240837335587, 0.002348054898902774, 0.03787226229906082, -0.0785246193408966, -0.11359238624572754, 0.052211660891771317, 0.07972294092178345, -0.018256613984704018, 0.010808249935507774, -0.08069567382335663, 0.03911193832755089, 0.03796018287539482, -0.027921967208385468, 0.034581851214170456, -0.024894041940569878, 0.10931583493947983, 0.0032324434723705053, -0.05208413302898407, 0.11619603633880615]\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model='all-MiniLM-L6-v2')\n",
    "\n",
    "sample_embeddings = embedding_model.embed_query(\"Hey How are you?\")\n",
    "print(f\"Length of sample embeddings : {len(sample_embeddings)}\")\n",
    "print(f\"Sample embedding : {sample_embeddings[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7ae16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
