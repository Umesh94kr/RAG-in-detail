{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0f07e3",
   "metadata": {},
   "source": [
    "#### **GraphRAG: Graph-Enhanced Retrieval-Augmented Generation**\n",
    "\n",
    "- GraphRAG is an advanced question-answering system that combines the power of graph-based knowledge representation with retrieval-augmented generation. \n",
    "- It processes input documents to create a rich knowledge graph, which is then used to enhance the retrieval and generation of answers to user queries. \n",
    "- The system leverages natural language processing, machine learning, and graph theory to provide more accurate and contextually relevant responses.\n",
    "\n",
    "#### **Motivation**\n",
    "\n",
    "Traditional retrieval-augmented generation systems often struggle with maintaining context over long documents and making connections between related pieces of information. GraphRAG addresses these limitations by:\n",
    "\n",
    "- Representing knowledge as an interconnected graph, allowing for better preservation of relationships between concepts.\n",
    "- Enabling more intelligent traversal of information during the query process.\n",
    "Providing a visual representation of how information is connected and accessed during the answering process.\n",
    "\n",
    "#### **Key Components**\n",
    "\n",
    "- **DocumentProcessor**: Handles the initial processing of input documents, creating text chunks and embeddings.\n",
    "\n",
    "- **KnowledgeGraph**: Constructs a graph representation of the processed documents, where nodes represent text chunks and edges represent relationships between them.\n",
    "\n",
    "- **QueryEngine**: Manages the process of answering user queries by leveraging the knowledge graph and vector store.\n",
    "\n",
    "- **Visualizer**: Creates a visual representation of the graph and the traversal path taken to answer a query.\n",
    "\n",
    "#### **Method Details**\n",
    "\n",
    "1) **Document Processing:** - \n",
    "    - Input documents are split into manageable chunks.\n",
    "    - Each chunk is embedded using a language model.\n",
    "    - A vector store is created from these embeddings for efficient similarity search.\n",
    "\n",
    "2) **Knowledge Graph Construction:** - \n",
    "    - Graph nodes are created for each text chunk.\n",
    "    - Concepts are extracted from each chunk using a combination of NLP techniques and language models.\n",
    "    - Extracted concepts are lemmatized to improve matching.\n",
    "    - Edges are added between nodes based on semantic similarity and shared concepts.\n",
    "    - Edge weights are calculated to represent the strength of relationships.\n",
    "\n",
    "3) **Query Processing**\n",
    "    - The user query is embedded and used to retrieve relevant documents from the vector store.\n",
    "    - A priority queue is initialized with the nodes corresponding to the most relevant documents.\n",
    "    - The system employs a Dijkstra-like algorithm to traverse the knowledge graph:\n",
    "        - Nodes are explored in order of their priority (strength of connection to the query).\n",
    "        - For each explored node:\n",
    "            - Its content is added to the context.\n",
    "            - The system checks if the current context provides a complete answer.\n",
    "            - If the answer is incomplete:\n",
    "                - The node's concepts are processed and added to a set of visited concepts.\n",
    "                - Neighboring nodes are explored, with their priorities updated based on edge weights.\n",
    "                - Nodes are added to the priority queue if a stronger connection is found.\n",
    "    - This process continues until a complete answer is found or the priority queue is exhausted.\n",
    "    - If no complete answer is found after traversing the graph, the system generates a final answer using the accumulated context and a large language model.\n",
    "\n",
    "4) #### **Vizualization** \n",
    "    - The knowledge graph is visualized with nodes representing text chunks and edges representing relationships.\n",
    "    - Edge colors indicate the strength of relationships (weights).\n",
    "    - The traversal path taken to answer a query is highlighted with curved, dashed arrows.\n",
    "    - Start and end nodes of the traversal are distinctly colored for easy identification.\n",
    "\n",
    "#### **Conclusion**\n",
    "\n",
    "- GraphRAG represents a significant advancement in retrieval-augmented generation systems. By incorporating a graph-based knowledge representation and intelligent traversal mechanisms, it offers improved context awareness, more accurate retrieval, and enhanced explainability. \n",
    "\n",
    "- The system's ability to visualize its decision-making process provides valuable insights into its operation, making it a powerful tool for both end-users and developers.\n",
    "\n",
    "- As natural language processing and graph-based AI continue to evolve, systems like GraphRAG pave the way for more sophisticated and capable question-answering technologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f12dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import List, Tuple, Dict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import spacy\n",
    "import heapq\n",
    "\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from spacy.cli import download\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Original path append replaced for Colab compatibility\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e48564",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **LLM used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ab658aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a language model, so I don't have emotions or feelings like humans do. However, I'm functioning properly and ready to assist you with any questions or tasks you may have! How can I help you today?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-12-27T16:05:53.242445Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18733557625, 'load_duration': 1688910500, 'prompt_eval_count': 30, 'prompt_eval_duration': 13846304875, 'eval_count': 47, 'eval_duration': 3195731958, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019b608e-de91-7591-a769-aadb09dcb2c0-0', usage_metadata={'input_tokens': 30, 'output_tokens': 47, 'total_tokens': 77})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama \n",
    "\n",
    "llm = ChatOllama(\n",
    "    model='llama3.2',\n",
    "    verbose=True,\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "llm.invoke(\"Hey How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028fc47",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Embedding Model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6763145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embeddings : 384\n",
      "Sample embeddings : [-0.013380538672208786, 0.003255972173064947, 0.10806030035018921, 0.08322358131408691, 0.02040085941553116, -0.049066152423620224, 0.0722508355975151, 0.002980925841256976, -0.08823534101247787, 0.016058299690485, -0.03367079421877861, -4.332493062975118e-06, -0.02510129101574421, 0.0007887802203185856, 0.060331884771585464, -0.0415474958717823, 0.07702311128377914, -0.14256997406482697, -0.13958506286144257, 0.06023767963051796, 0.003192346775904298, 0.018982844427227974, 0.02300790697336197, 0.06056844815611839, -0.07911035418510437, -0.05399537831544876, -0.0008475205395370722, 0.03202424943447113, -0.029674910008907318, -0.04484577104449272, -0.10411098599433899, 0.06399180740118027, -0.05713418126106262, -0.02695028856396675, -0.028776653110980988, 0.00333896791562438, -0.0355900302529335, -0.13525626063346863, 0.009469274431467056, 0.0003555373114068061, 0.009924577549099922, -0.0014938903041183949, -0.009747199714183807, -0.0021706046536564827, 0.06437141448259354, -0.04134561866521835, -0.015959464013576508, 0.07168345153331757, 0.09831950813531876, 0.010891384445130825, -0.10564935207366943, -0.06154218316078186, -0.04495823755860329, 0.03288338705897331, 0.06448811292648315, 0.026930589228868484, -0.022059716284275055, 0.008090948686003685, 0.0885234996676445, -0.040078986436128616, -0.011959749273955822, 0.025354033336043358, -0.10569483041763306, 0.0038036201149225235, 0.059116121381521225, -0.016421761363744736, -0.06289204210042953, -0.03538224473595619, -0.03384290635585785, -0.05755750089883804, -0.01964549534022808, -0.07316037267446518, 0.03075730986893177, -0.017475150525569916, 0.029496576637029648, -0.08609264343976974, 0.052657350897789, -0.04254796728491783, 0.03953508660197258, 0.04585482180118561, 0.06450486183166504, -0.06745240837335587, 0.002348054898902774, 0.03787226229906082, -0.0785246193408966, -0.11359238624572754, 0.052211660891771317, 0.07972294092178345, -0.018256613984704018, 0.010808249935507774, -0.08069567382335663, 0.03911193832755089, 0.03796018287539482, -0.027921967208385468, 0.034581851214170456, -0.024894041940569878, 0.10931583493947983, 0.0032324434723705053, -0.05208413302898407, 0.11619603633880615]\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings \n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = embedding_model.embed_query(\"Hey How are you?\")\n",
    "print(f\"Length of embeddings : {len(embeddings)}\")\n",
    "print(f\"Sample embeddings : {embeddings[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79cea7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Document Processor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17ac3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DocumentProcessor class\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, llm, embedding_model):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "        self.llm = llm\n",
    "        self.embedding_model = embedding_model \n",
    "\n",
    "    def process_documents(self, documents):\n",
    "        splits = self.text_splitter.split_documents(documents)\n",
    "        vector_store = FAISS.from_documents(splits, self.embeddings)\n",
    "        return splits, vector_store\n",
    "\n",
    "    def create_embeddings_batch(self, texts, batch_size=32):\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            batch_embeddings = self.embeddings.embed_documents(batch)\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def compute_similarity_matrix(self, embeddings):\n",
    "        return cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Concepts class\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Annotated\n",
    "\n",
    "class Concepts(BaseModel):\n",
    "    concepts_list: Annotated[List[str], Field(description=\"List of concepts\")]\n",
    "\n",
    "# Define the KnowledgeGraph class\n",
    "class KnowledgeGraph:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.Graph()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.concept_cache = {}\n",
    "        self.nlp = self._load_spacy_model()\n",
    "        self.edges_threshold = 0.8\n",
    "\n",
    "    def build_graph(self, splits, llm, embedding_model):\n",
    "        self._add_nodes(splits)\n",
    "        embeddings = self._create_embeddings(splits, embedding_model)\n",
    "        self._extract_concepts(splits, llm)\n",
    "        self._add_edges(embeddings)\n",
    "\n",
    "    def _add_nodes(self, splits):\n",
    "        for i, split in enumerate(splits):\n",
    "            self.graph.add_node(i, content=split.page_content)\n",
    "\n",
    "    def _create_embeddings(self, splits, embedding_model):\n",
    "        texts = [split.page_content for split in splits]\n",
    "        return embedding_model.embed_documents(texts)\n",
    "\n",
    "    def _compute_similarities(self, embeddings):\n",
    "        return cosine_similarity(embeddings)\n",
    "\n",
    "    def _load_spacy_model(self):\n",
    "        try:\n",
    "            return spacy.load(\"en_core_web_sm\")\n",
    "        except OSError:\n",
    "            print(\"Downloading spaCy model...\")\n",
    "            download(\"en_core_web_sm\")\n",
    "            return spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def _extract_concepts_and_entities(self, content, llm):\n",
    "        if content in self.concept_cache:\n",
    "            return self.concept_cache[content]\n",
    "        # Extract named entities using spaCy\n",
    "        doc = self.nlp(content)\n",
    "        named_entities = [ent.text for ent in doc.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\", \"WORK_OF_ART\"]]\n",
    "\n",
    "        # Extract general concepts using LLM\n",
    "        concept_extraction_prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"Extract key concepts (excluding named entities) from the following text:\\n\\n{text}\\n\\nKey concepts:\"\n",
    "        )\n",
    "        concept_chain = concept_extraction_prompt | llm.with_structured_output(Concepts)\n",
    "        general_concepts = concept_chain.invoke({\"text\": content}).concepts_list\n",
    "        \n",
    "        # Combine named entities and general concepts\n",
    "        all_concepts = list(set(named_entities + general_concepts))\n",
    "        self.concept_cache[content] = all_concepts\n",
    "        return all_concepts\n",
    "\n",
    "    def _extract_concepts(self, splits, llm):\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            future_to_node = {executor.submit(self._extract_concepts_and_entities, split.page_content, llm): i \n",
    "                              for i, split in enumerate(splits)}\n",
    "            \n",
    "            for future in tqdm(as_completed(future_to_node), total=len(splits), desc=\"Extracting concepts and entities\"):\n",
    "                node = future_to_node[future]\n",
    "                concepts = future.result()\n",
    "                self.graph.nodes[node]['concepts'] = concepts\n",
    "\n",
    "    def _add_edges(self, embeddings):\n",
    "        similarity_matrix = self._compute_similarities(embeddings)\n",
    "        num_nodes = len(self.graph.nodes)\n",
    "        \n",
    "        for node1 in tqdm(range(num_nodes), desc=\"Adding edges\"):\n",
    "            for node2 in range(node1 + 1, num_nodes):\n",
    "                similarity_score = similarity_matrix[node1][node2]\n",
    "                if similarity_score > self.edges_threshold:\n",
    "                    shared_concepts = set(self.graph.nodes[node1]['concepts']) & set(self.graph.nodes[node2]['concepts'])\n",
    "                    edge_weight = self._calculate_edge_weight(node1, node2, similarity_score, shared_concepts)\n",
    "                    self.graph.add_edge(node1, node2, weight=edge_weight, \n",
    "                                        similarity=similarity_score,\n",
    "                                        shared_concepts=list(shared_concepts))\n",
    "\n",
    "    def _calculate_edge_weight(self, node1, node2, similarity_score, shared_concepts, alpha=0.7, beta=0.3):\n",
    "        max_possible_shared = min(len(self.graph.nodes[node1]['concepts']), len(self.graph.nodes[node2]['concepts']))\n",
    "        normalized_shared_concepts = len(shared_concepts) / max_possible_shared if max_possible_shared > 0 else 0\n",
    "        return alpha * similarity_score + beta * normalized_shared_concepts\n",
    "\n",
    "    def _lemmatize_concept(self, concept):\n",
    "        return ' '.join([self.lemmatizer.lemmatize(word) for word in concept.lower().split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AnswerCheck class\n",
    "class AnswerCheck(BaseModel):\n",
    "    is_complete: bool = Field(description=\"Whether the current context provides a complete answer to the query\")\n",
    "    answer: str = Field(description=\"The current answer based on the context, if any\")\n",
    "\n",
    "# Define the QueryEngine class\n",
    "class QueryEngine:\n",
    "    def __init__(self, vector_store, knowledge_graph, llm):\n",
    "        self.vector_store = vector_store\n",
    "        self.knowledge_graph = knowledge_graph\n",
    "        self.llm = llm\n",
    "        self.max_context_length = 4000\n",
    "        self.answer_check_chain = self._create_answer_check_chain()\n",
    "\n",
    "    def _create_answer_check_chain(self):\n",
    "        answer_check_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"context\"],\n",
    "            template=\"Given the query: '{query}'\\n\\nAnd the current context:\\n{context}\\n\\nDoes this context provide a complete answer to the query? If yes, provide the answer. If no, state that the answer is incomplete.\\n\\nIs complete answer (Yes/No):\\nAnswer (if complete):\"\n",
    "        )\n",
    "        return answer_check_prompt | self.llm.with_structured_output(AnswerCheck)\n",
    "\n",
    "    def _check_answer(self, query: str, context: str) -> Tuple[bool, str]:\n",
    "        response = self.answer_check_chain.invoke({\"query\": query, \"context\": context})\n",
    "        return response.is_complete, response.answer\n",
    "\n",
    "  \n",
    "\n",
    "    def _expand_context(self, query: str, relevant_docs) -> Tuple[str, List[int], Dict[int, str], str]:\n",
    "        # Initialize variables\n",
    "        expanded_context = \"\"\n",
    "        traversal_path = []\n",
    "        visited_concepts = set()\n",
    "        filtered_content = {}\n",
    "        final_answer = \"\"\n",
    "        \n",
    "        priority_queue = []\n",
    "        distances = {}  # Stores the best known \"distance\" (inverse of connection strength) to each node\n",
    "        \n",
    "        print(\"\\nTraversing the knowledge graph:\")\n",
    "        \n",
    "        # Initialize priority queue with closest nodes from relevant docs\n",
    "        for doc in relevant_docs:\n",
    "            # Find the most similar node in the knowledge graph for each relevant document\n",
    "            closest_nodes = self.vector_store.similarity_search_with_score(doc.page_content, k=1)\n",
    "            closest_node_content, similarity_score = closest_nodes[0]\n",
    "            \n",
    "            # Get the corresponding node in our knowledge graph\n",
    "            closest_node = next(n for n in self.knowledge_graph.graph.nodes if self.knowledge_graph.graph.nodes[n]['content'] == closest_node_content.page_content)\n",
    "            \n",
    "            # Initialize priority (inverse of similarity score for min-heap behavior)\n",
    "            priority = 1 / similarity_score\n",
    "            heapq.heappush(priority_queue, (priority, closest_node))\n",
    "            distances[closest_node] = priority\n",
    "        \n",
    "        step = 0\n",
    "        while priority_queue:\n",
    "            # Get the node with the highest priority (lowest distance value)\n",
    "            current_priority, current_node = heapq.heappop(priority_queue)\n",
    "            \n",
    "            # Skip if we've already found a better path to this node\n",
    "            if current_priority > distances.get(current_node, float('inf')):\n",
    "                continue\n",
    "            \n",
    "            if current_node not in traversal_path:\n",
    "                step += 1\n",
    "                traversal_path.append(current_node)\n",
    "                node_content = self.knowledge_graph.graph.nodes[current_node]['content']\n",
    "                node_concepts = self.knowledge_graph.graph.nodes[current_node]['concepts']\n",
    "                \n",
    "                # Add node content to our accumulated context\n",
    "                filtered_content[current_node] = node_content\n",
    "                expanded_context += \"\\n\" + node_content if expanded_context else node_content\n",
    "                \n",
    "                # Log the current step for debugging and visualization\n",
    "                print(f\"\\nStep {step} - Node {current_node}:\")\n",
    "                print(f\"Content: {node_content[:100]}...\") \n",
    "                print(f\"Concepts: {', '.join(node_concepts)}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "                # Check if we have a complete answer with the current context\n",
    "                is_complete, answer = self._check_answer(query, expanded_context)\n",
    "                if is_complete:\n",
    "                    final_answer = answer\n",
    "                    break\n",
    "                \n",
    "                # Process the concepts of the current node\n",
    "                node_concepts_set = set(self.knowledge_graph._lemmatize_concept(c) for c in node_concepts)\n",
    "                if not node_concepts_set.issubset(visited_concepts):\n",
    "                    visited_concepts.update(node_concepts_set)\n",
    "                    \n",
    "                    # Explore neighbors\n",
    "                    for neighbor in self.knowledge_graph.graph.neighbors(current_node):\n",
    "                        edge_data = self.knowledge_graph.graph[current_node][neighbor]\n",
    "                        edge_weight = edge_data['weight']\n",
    "                        \n",
    "                        # Calculate new distance (priority) to the neighbor\n",
    "                        # Note: We use 1 / edge_weight because higher weights mean stronger connections\n",
    "                        distance = current_priority + (1 / edge_weight)\n",
    "                        \n",
    "                        # If we've found a stronger connection to the neighbor, update its distance\n",
    "                        if distance < distances.get(neighbor, float('inf')):\n",
    "                            distances[neighbor] = distance\n",
    "                            heapq.heappush(priority_queue, (distance, neighbor))\n",
    "                            \n",
    "                            # Process the neighbor node if it's not already in our traversal path\n",
    "                            if neighbor not in traversal_path:\n",
    "                                step += 1\n",
    "                                traversal_path.append(neighbor)\n",
    "                                neighbor_content = self.knowledge_graph.graph.nodes[neighbor]['content']\n",
    "                                neighbor_concepts = self.knowledge_graph.graph.nodes[neighbor]['concepts']\n",
    "                                \n",
    "                                filtered_content[neighbor] = neighbor_content\n",
    "                                expanded_context += \"\\n\" + neighbor_content if expanded_context else neighbor_content\n",
    "                                \n",
    "                                # Log the neighbor node information\n",
    "                                print(f\"\\nStep {step} - Node {neighbor} (neighbor of {current_node}):\")\n",
    "                                print(f\"Content: {neighbor_content[:100]}...\")\n",
    "                                print(f\"Concepts: {', '.join(neighbor_concepts)}\")\n",
    "                                print(\"-\" * 50)\n",
    "                                \n",
    "                                # Check if we have a complete answer after adding the neighbor's content\n",
    "                                is_complete, answer = self._check_answer(query, expanded_context)\n",
    "                                if is_complete:\n",
    "                                    final_answer = answer\n",
    "                                    break\n",
    "                                \n",
    "                                # Process the neighbor's concepts\n",
    "                                neighbor_concepts_set = set(self.knowledge_graph._lemmatize_concept(c) for c in neighbor_concepts)\n",
    "                                if not neighbor_concepts_set.issubset(visited_concepts):\n",
    "                                    visited_concepts.update(neighbor_concepts_set)\n",
    "                \n",
    "                # If we found a final answer, break out of the main loop\n",
    "                if final_answer:\n",
    "                    break\n",
    "\n",
    "        # If we haven't found a complete answer, generate one using the LLM\n",
    "        if not final_answer:\n",
    "            print(\"\\nGenerating final answer...\")\n",
    "            response_prompt = PromptTemplate(\n",
    "                input_variables=[\"query\", \"context\"],\n",
    "                template=\"Based on the following context, please answer the query.\\n\\nContext: {context}\\n\\nQuery: {query}\\n\\nAnswer:\"\n",
    "            )\n",
    "            response_chain = response_prompt | self.llm\n",
    "            input_data = {\"query\": query, \"context\": expanded_context}\n",
    "            final_answer = response_chain.invoke(input_data)\n",
    "\n",
    "        return expanded_context, traversal_path, filtered_content, final_answer\n",
    "\n",
    "    def query(self, query: str) -> Tuple[str, List[int], Dict[int, str]]:\n",
    "        with get_openai_callback() as cb:\n",
    "            print(f\"\\nProcessing query: {query}\")\n",
    "            relevant_docs = self._retrieve_relevant_documents(query)\n",
    "            expanded_context, traversal_path, filtered_content, final_answer = self._expand_context(query, relevant_docs)\n",
    "            \n",
    "            if not final_answer:\n",
    "                print(\"\\nGenerating final answer...\")\n",
    "                response_prompt = PromptTemplate(\n",
    "                    input_variables=[\"query\", \"context\"],\n",
    "                    template=\"Based on the following context, please answer the query.\\n\\nContext: {context}\\n\\nQuery: {query}\\n\\nAnswer:\"\n",
    "                )\n",
    "                \n",
    "                response_chain = response_prompt | self.llm\n",
    "                input_data = {\"query\": query, \"context\": expanded_context}\n",
    "                response = response_chain.invoke(input_data)\n",
    "                final_answer = response\n",
    "            else:\n",
    "                print(\"\\nComplete answer found during traversal.\")\n",
    "            \n",
    "            print(f\"\\nFinal Answer: {final_answer}\")\n",
    "            print(f\"\\nTotal Tokens: {cb.total_tokens}\")\n",
    "            print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
    "            print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
    "            print(f\"Total Cost (USD): ${cb.total_cost}\")\n",
    "        \n",
    "        return final_answer, traversal_path, filtered_content\n",
    "\n",
    "    def _retrieve_relevant_documents(self, query: str):\n",
    "        print(\"\\nRetrieving relevant documents...\")\n",
    "        retriever = self.vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "        compressor = LLMChainExtractor.from_llm(self.llm)\n",
    "        compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever)\n",
    "        return compression_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a439cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Define the Visualizer class\n",
    "class Visualizer:\n",
    "    @staticmethod\n",
    "    def visualize_traversal(graph, traversal_path):\n",
    "        traversal_graph = nx.DiGraph()\n",
    "        \n",
    "        # Add nodes and edges from the original graph\n",
    "        for node in graph.nodes():\n",
    "            traversal_graph.add_node(node)\n",
    "        for u, v, data in graph.edges(data=True):\n",
    "            traversal_graph.add_edge(u, v, **data)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(16, 12))\n",
    "        \n",
    "        # Generate positions for all nodes\n",
    "        pos = nx.spring_layout(traversal_graph, k=1, iterations=50)\n",
    "        \n",
    "        # Draw regular edges with color based on weight\n",
    "        edges = traversal_graph.edges()\n",
    "        edge_weights = [traversal_graph[u][v].get('weight', 0.5) for u, v in edges]\n",
    "        nx.draw_networkx_edges(traversal_graph, pos, \n",
    "                               edgelist=edges,\n",
    "                               edge_color=edge_weights,\n",
    "                               edge_cmap=plt.cm.Blues,\n",
    "                               width=2,\n",
    "                               ax=ax)\n",
    "        \n",
    "        # Draw nodes\n",
    "        nx.draw_networkx_nodes(traversal_graph, pos, \n",
    "                               node_color='lightblue',\n",
    "                               node_size=3000,\n",
    "                               ax=ax)\n",
    "        \n",
    "        # Draw traversal path with curved arrows\n",
    "        edge_offset = 0.1\n",
    "        for i in range(len(traversal_path) - 1):\n",
    "            start = traversal_path[i]\n",
    "            end = traversal_path[i + 1]\n",
    "            start_pos = pos[start]\n",
    "            end_pos = pos[end]\n",
    "            \n",
    "            # Calculate control point for curve\n",
    "            mid_point = ((start_pos[0] + end_pos[0]) / 2, (start_pos[1] + end_pos[1]) / 2)\n",
    "            control_point = (mid_point[0] + edge_offset, mid_point[1] + edge_offset)\n",
    "            \n",
    "            # Draw curved arrow\n",
    "            arrow = patches.FancyArrowPatch(start_pos, end_pos,\n",
    "                                            connectionstyle=f\"arc3,rad={0.3}\",\n",
    "                                            color='red',\n",
    "                                            arrowstyle=\"->\",\n",
    "                                            mutation_scale=20,\n",
    "                                            linestyle='--',\n",
    "                                            linewidth=2,\n",
    "                                            zorder=4)\n",
    "            ax.add_patch(arrow)\n",
    "        \n",
    "        # Prepare labels for the nodes\n",
    "        labels = {}\n",
    "        for i, node in enumerate(traversal_path):\n",
    "            concepts = graph.nodes[node].get('concepts', [])\n",
    "            label = f\"{i + 1}. {concepts[0] if concepts else ''}\"\n",
    "            labels[node] = label\n",
    "        \n",
    "        for node in traversal_graph.nodes():\n",
    "            if node not in labels:\n",
    "                concepts = graph.nodes[node].get('concepts', [])\n",
    "                labels[node] = concepts[0] if concepts else ''\n",
    "        \n",
    "        # Draw labels\n",
    "        nx.draw_networkx_labels(traversal_graph, pos, labels, font_size=8, font_weight=\"bold\", ax=ax)\n",
    "        \n",
    "        # Highlight start and end nodes\n",
    "        start_node = traversal_path[0]\n",
    "        end_node = traversal_path[-1]\n",
    "        \n",
    "        nx.draw_networkx_nodes(traversal_graph, pos, \n",
    "                               nodelist=[start_node], \n",
    "                               node_color='lightgreen', \n",
    "                               node_size=3000,\n",
    "                               ax=ax)\n",
    "        \n",
    "        nx.draw_networkx_nodes(traversal_graph, pos, \n",
    "                               nodelist=[end_node], \n",
    "                               node_color='lightcoral', \n",
    "                               node_size=3000,\n",
    "                               ax=ax)\n",
    "        \n",
    "        ax.set_title(\"Graph Traversal Flow\")\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add colorbar for edge weights\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.Blues, norm=plt.Normalize(vmin=min(edge_weights), vmax=max(edge_weights)))\n",
    "        sm.set_array([])\n",
    "        cbar = fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Edge Weight', rotation=270, labelpad=15)\n",
    "        \n",
    "        # Add legend\n",
    "        regular_line = plt.Line2D([0], [0], color='blue', linewidth=2, label='Regular Edge')\n",
    "        traversal_line = plt.Line2D([0], [0], color='red', linewidth=2, linestyle='--', label='Traversal Path')\n",
    "        start_point = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightgreen', markersize=15, label='Start Node')\n",
    "        end_point = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightcoral', markersize=15, label='End Node')\n",
    "        legend = plt.legend(handles=[regular_line, traversal_line, start_point, end_point], loc='upper left', bbox_to_anchor=(0, 1), ncol=2)\n",
    "        legend.get_frame().set_alpha(0.8)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def print_filtered_content(traversal_path, filtered_content):\n",
    "        print(\"\\nFiltered content of visited nodes in order of traversal:\")\n",
    "        for i, node in enumerate(traversal_path):\n",
    "            print(f\"\\nStep {i + 1} - Node {node}:\")\n",
    "            print(f\"Filtered Content: {filtered_content.get(node, 'No filtered content available')[:200]}...\")  # Print first 200 characters\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb \n",
    "\n",
    "class GraphRAG:\n",
    "    def __init__(self, llm, embedding_model):\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", max_tokens=4000)\n",
    "        self.embedding_model = embedding_model\n",
    "        self.document_processor = llm\n",
    "        self.knowledge_graph = KnowledgeGraph()\n",
    "        self.query_engine = None\n",
    "        self.visualizer = Visualizer()\n",
    "\n",
    "    def process_documents(self, documents):\n",
    "        splits, vector_store = self.document_processor.process_documents(documents)\n",
    "        pdb.set_trace()\n",
    "        self.knowledge_graph.build_graph(splits, self.llm, self.embedding_model)\n",
    "        pdb.set_trace()\n",
    "        self.query_engine = QueryEngine(vector_store, self.knowledge_graph, self.llm)\n",
    "\n",
    "    def query(self, query: str):\n",
    "        response, traversal_path, filtered_content = self.query_engine.query(query)\n",
    "        pdb.set_trace()\n",
    "        if traversal_path:\n",
    "            self.visualizer.visualize_traversal(self.knowledge_graph.graph, traversal_path)\n",
    "        else:\n",
    "            print(\"No traversal path to visualize.\")\n",
    "        pdb.set_trace()\n",
    "        return response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
