{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3238906",
   "metadata": {},
   "source": [
    "## üìò **Workflow of a Reliable RAG System**\n",
    "\n",
    "A reliable RAG pipeline does not just *retrieve* and *generate* responses ‚Äî  \n",
    "it also **checks retrieval quality**, **checks hallucination**, and **tracks which context influenced the answer**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ **1) Query ‚Üí Retriever ‚Üí Retrieved Documents**\n",
    "\n",
    "##### ‚úîÔ∏è *LLM-Based Relevancy Check*\n",
    "After retrieving documents, use an LLM to evaluate:\n",
    "\n",
    "- Are the retrieved documents actually relevant to the query?\n",
    "- Are they sufficient to answer it?\n",
    "- Do we need a retry with different retrieval parameters?\n",
    "\n",
    "This prevents garbage context from reaching the generator.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ **2) Retrieved Docs + Query ‚Üí System Prompt ‚Üí LLM ‚Üí Response**\n",
    "\n",
    "##### ‚úîÔ∏è *Hallucination Check*\n",
    "Use another LLM pass to verify:\n",
    "\n",
    "- Does the **generated response** align with the **retrieved context**?\n",
    "- Are there statements not supported by context?\n",
    "- Should the response be revised?\n",
    "\n",
    "This ensures factual grounding.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ **3) Evidence Tracking ‚Üí Highlight the Context Used**\n",
    "\n",
    "Finally, ask the LLM to identify **which specific lines/snippets** from the retrieved documents were actually used to generate the response.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c43d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm just a language model, so I don't have feelings or emotions like humans do. However, I'm functioning properly and ready to assist you with any questions or tasks you may have! How can I help you today?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-12-03T15:45:34.062656Z', 'done': True, 'done_reason': 'stop', 'total_duration': 21391342750, 'load_duration': 3658086167, 'prompt_eval_count': 29, 'prompt_eval_duration': 12826979792, 'eval_count': 47, 'eval_duration': 3510671920, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--14b6c7c9-7444-458c-8de7-be184513c802-0', usage_metadata={'input_tokens': 29, 'output_tokens': 47, 'total_tokens': 76})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Specify LLM \n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "llm.invoke(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48a3b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# login to huggingface\n",
    "import os\n",
    "from huggingface_hub import login \n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbe124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embeddings : 384\n",
      "Embedding : [-0.013380538672208786, 0.003255972173064947, 0.10806030035018921, 0.08322358131408691, 0.02040085941553116, -0.049066152423620224, 0.0722508355975151, 0.002980925841256976, -0.08823534101247787, 0.016058299690485, -0.03367079421877861, -4.332493062975118e-06, -0.02510129101574421, 0.0007887802203185856, 0.060331884771585464, -0.0415474958717823, 0.07702311128377914, -0.14256997406482697, -0.13958506286144257, 0.06023767963051796, 0.003192346775904298, 0.018982844427227974, 0.02300790697336197, 0.06056844815611839, -0.07911035418510437, -0.05399537831544876, -0.0008475205395370722, 0.03202424943447113, -0.029674910008907318, -0.04484577104449272, -0.10411098599433899, 0.06399180740118027, -0.05713418126106262, -0.02695028856396675, -0.028776653110980988, 0.00333896791562438, -0.0355900302529335, -0.13525626063346863, 0.009469274431467056, 0.0003555373114068061, 0.009924577549099922, -0.0014938903041183949, -0.009747199714183807, -0.0021706046536564827, 0.06437141448259354, -0.04134561866521835, -0.015959464013576508, 0.07168345153331757, 0.09831950813531876, 0.010891384445130825, -0.10564935207366943, -0.06154218316078186, -0.04495823755860329, 0.03288338705897331, 0.06448811292648315, 0.026930589228868484, -0.022059716284275055, 0.008090948686003685, 0.0885234996676445, -0.040078986436128616, -0.011959749273955822, 0.025354033336043358, -0.10569483041763306, 0.0038036201149225235, 0.059116121381521225, -0.016421761363744736, -0.06289204210042953, -0.03538224473595619, -0.03384290635585785, -0.05755750089883804, -0.01964549534022808, -0.07316037267446518, 0.03075730986893177, -0.017475150525569916, 0.029496576637029648, -0.08609264343976974, 0.052657350897789, -0.04254796728491783, 0.03953508660197258, 0.04585482180118561, 0.06450486183166504, -0.06745240837335587, 0.002348054898902774, 0.03787226229906082, -0.0785246193408966, -0.11359238624572754, 0.052211660891771317, 0.07972294092178345, -0.018256613984704018, 0.010808249935507774, -0.08069567382335663, 0.03911193832755089, 0.03796018287539482, -0.027921967208385468, 0.034581851214170456, -0.024894041940569878, 0.10931583493947983, 0.0032324434723705053, -0.05208413302898407, 0.11619603633880615]\n"
     ]
    }
   ],
   "source": [
    "# for embedding model we'll use sentence-transformers\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "# sample embedding \n",
    "embeddings = embedding_model.embed_query(\"Hey How are you?\")\n",
    "print(f\"Length of embeddings : {len(embeddings)}\")\n",
    "print(f\"Embedding : {embeddings[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c924d1",
   "metadata": {},
   "source": [
    "## Loading Docs -> Chunking (Making ready for VectoreDB)\n",
    "\n",
    "This time we'll use `WebBaseLoader` from langchain to fetch content from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bff9abd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use some URLs of 'The Batch' newsletter of Andrew NG\n",
    "urls = [\n",
    "    \"https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io\",\n",
    "    \"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32937370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use WebBaseLoader to load the content from URLs\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef139797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance‚ú® New '\n",
      " 'course! Enroll in Building Coding Agents with Tool ExecutionExplore '\n",
      " \"CoursesAI NewsletterThe BatchAndrew's LetterData PointsML ResearchBlog‚ú® AI \"\n",
      " 'Dev x SF 26CommunityForumEventsAmbassadorsAmbassador '\n",
      " \"SpotlightResourcesMembershipStart LearningWeekly IssuesAndrew's LettersData \"\n",
      " 'PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe '\n",
      " 'BatchLettersArticleAgentic Design Patterns Part 1 Four AI agent strategies '\n",
      " 'that improve GPT-4 and GPT-3.5 performanceLettersTechnical '\n",
      " 'InsightsPublishedMar 20, 2024Reading time2 min readShareDear friends,I think '\n",
      " 'AI agent workflows will drive massive AI progress this year ‚Äî perhaps even '\n",
      " 'more than the next generation of foundation models. This is an important '\n",
      " 'trend, and I urge everyone who works in AI to pay attention to it.Today, we '\n",
      " 'mostly use LLMs in zero-shot mode, prompting a model to generate final '\n",
      " 'output token by token without revising its work. This is akin to asking '\n",
      " 'someone to compose an essay from start to finish, typing straight through '\n",
      " 'with no backspacing allowed, and expecting a high-quality result. Despite '\n",
      " 'the difficulty, LLMs do amazingly well at this task!\\xa0With an agent '\n",
      " 'workflow, however, we can ask the LLM to iterate over a document many times. '\n",
      " 'For example, it might take a sequence of steps such as:Plan an '\n",
      " 'outline.Decide what, if any, web searches are needed to gather more '\n",
      " 'information.Write a first draft.Read over the first draft to spot '\n",
      " 'unjustified arguments or extraneous information.Revise the draft taking into '\n",
      " 'account any weaknesses spotted.And so on.This iterative process is critical '\n",
      " 'for most human writers to write good text. With AI, such an iterative '\n",
      " 'workflow yields much better results than writing in a single pass.\\xa0'\n",
      " 'Devin‚Äôs splashy demo recently received a lot of social media buzz. My team '\n",
      " 'has been closely following the evolution of AI that writes code. We analyzed '\n",
      " 'results from a number of research teams, focusing on an algorithm‚Äôs ability '\n",
      " 'to do well on the widely used HumanEval coding benchmark. You can see our '\n",
      " 'findings in the diagram below.\\xa0GPT-3.5 (zero shot) was 48.1% correct. '\n",
      " 'GPT-4 (zero shot) does better at 67.0%. However, the improvement from '\n",
      " 'GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. '\n",
      " 'Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.\\xa0Open '\n",
      " 'source agent tools and the academic literature on agents are proliferating, '\n",
      " 'making this an exciting time but also a confusing one. To help put this work '\n",
      " 'into perspective, I‚Äôd like to share a framework for categorizing design '\n",
      " 'patterns for building agents. My team AI Fund is successfully using these '\n",
      " 'patterns in many applications, and I hope you find them useful.Reflection: '\n",
      " 'The LLM examines its own work to come up with ways to improve it.\\xa0Tool '\n",
      " 'Use: The LLM is given tools such as web search, code execution, or any other '\n",
      " 'function to help it gather information, take action, or process '\n",
      " 'data.Planning: The LLM comes up with, and executes, a multistep plan to '\n",
      " 'achieve a goal (for example, writing an outline for an essay, then doing '\n",
      " 'online research, then writing a draft, and so on).Multi-agent collaboration: '\n",
      " 'More than one AI agent work together, splitting up tasks and discussing and '\n",
      " 'debating ideas, to come up with better solutions than a single agent '\n",
      " 'would.Next week, I‚Äôll elaborate on these design patterns and offer suggested '\n",
      " 'readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: '\n",
      " 'Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic '\n",
      " 'Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: '\n",
      " 'Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with '\n",
      " 'weekly AI News and Insights delivered to your inboxCoursesThe '\n",
      " 'BatchCommunityCareersAboutContactHelp\\n')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(docs[0][0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77a7174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of docs\n",
    "docs_list = [item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb9c47e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io', 'title': 'Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance', 'description': 'I think AI agent workflows will drive massive AI progress this year ‚Äî perhaps even more than the next generation of foundation models. This is an important...', 'language': 'en'}, page_content='Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance‚ú® New course! Enroll in Building Coding Agents with Tool ExecutionExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev x SF 26CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesMembershipStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 1 Four AI agent strategies that improve GPT-4 and GPT-3.5 performanceLettersTechnical InsightsPublishedMar 20, 2024Reading time2 min readShareDear friends,I think AI agent workflows will drive massive AI progress this year ‚Äî perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.Today, we mostly use LLMs in zero-shot mode, prompting a model to generate final output token by token without revising its work. This is akin to asking someone to compose an essay from start to finish, typing straight through with no backspacing allowed, and expecting a high-quality result. Despite the difficulty, LLMs do amazingly well at this task!\\xa0With an agent workflow, however, we can ask the LLM to iterate over a document many times. For example, it might take a sequence of steps such as:Plan an outline.Decide what, if any, web searches are needed to gather more information.Write a first draft.Read over the first draft to spot unjustified arguments or extraneous information.Revise the draft taking into account any weaknesses spotted.And so on.This iterative process is critical for most human writers to write good text. With AI, such an iterative workflow yields much better results than writing in a single pass.\\xa0Devin‚Äôs splashy demo recently received a lot of social media buzz. My team has been closely following the evolution of AI that writes code. We analyzed results from a number of research teams, focusing on an algorithm‚Äôs ability to do well on the widely used HumanEval coding benchmark. You can see our findings in the diagram below.\\xa0GPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.\\xa0Open source agent tools and the academic literature on agents are proliferating, making this an exciting time but also a confusing one. To help put this work into perspective, I‚Äôd like to share a framework for categorizing design patterns for building agents. My team AI Fund is successfully using these patterns in many applications, and I hope you find them useful.Reflection: The LLM examines its own work to come up with ways to improve it.\\xa0Tool Use: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.Planning: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).Multi-agent collaboration: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.Next week, I‚Äôll elaborate on these design patterns and offer suggested readings for each.Keep learning!AndrewRead \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp\\n'),\n",
       " Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 2: Reflection', 'description': 'Last week, I described four design patterns for AI agentic workflows that I believe will drive significant progress this year: Reflection, Tool use...', 'language': 'en'}, page_content='Agentic Design Patterns Part 2: Reflection‚ú® New course! Enroll in Building Coding Agents with Tool ExecutionExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev x SF 26CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesMembershipStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 2, Reflection Large language models can become more effective agents by reflecting on their own behavior.LettersTechnical InsightsPublishedMar 27, 2024Reading time2 min readShareDear friends,Last week, I described four design patterns for AI agentic workflows that I believe will drive significant progress this year: Reflection, Tool Use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. In this letter, I\\'d like to discuss Reflection. For a design pattern that‚Äôs relatively quick to implement, I\\'ve seen it lead to surprising performance gains.\\xa0You may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection.\\xa0Take the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. After that, we can prompt it to reflect on its own output, perhaps as follows:Here‚Äôs code intended for task X: [previously generated code]\\xa0 \\xa0\\xa0Check the code carefully for correctness, style, and efficiency, and give constructive criticism for how to improve it.Sometimes this causes the LLM to spot problems and come up with constructive suggestions. Next, we can prompt the LLM with context including (i) the previously generated code and the constructive feedback and (ii) ask it to use the feedback to rewrite the code. This can lead to a better response. Repeating the criticism/rewrite process might yield further improvements. This self-reflection process allows the LLM to spot gaps and improve its output on a variety of tasks including producing code, writing text, and answering questions.\\xa0And we can go beyond self-reflection by giving the LLM tools that help evaluate its output; for example, running its code through a few unit tests to check whether it generates correct results on test cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement.Further, we can implement Reflection using a multi-agent framework. I\\'ve found it convenient to create two different agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent\\'s output. The resulting discussion between the two agents leads to improved responses.Reflection is a relatively basic type of agentic workflow, but I\\'ve been delighted by how much it improved my applications‚Äô results in a few cases. I hope you will try it in your own work. If you‚Äôre interested in learning more about reflection, I recommend these papers:‚ÄúSelf-Refine: Iterative Refinement with Self-Feedback,‚Äù Madaan et al. (2023)‚ÄúReflexion: Language Agents with Verbal Reinforcement Learning,‚Äù Shinn et al. (2023)‚ÄúCRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing,‚Äù Gou et al. (2024)I‚Äôll discuss the other agentic design patterns in future letters.Keep learning!Andrew\\xa0Read \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp\\n'),\n",
       " Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 3: Tool Use', 'description': 'Tool use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design...', 'language': 'en'}, page_content='Agentic Design Patterns Part 3: Tool Use‚ú® New course! Enroll in Building Coding Agents with Tool ExecutionExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev x SF 26CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesMembershipStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 3, Tool Use How large language models can act as agents by taking advantage of external tools for search, code execution, productivity, ad infinitumLettersTechnical InsightsApril 03, 2024PublishedApr 3, 2024Reading time3 min readShareDear friends,Tool Use, in which an LLM is given functions it can request to call for gathering information, taking action, or manipulating data, is a key design pattern of\\xa0AI agentic workflows. You may be familiar with LLM-based systems that can perform a web search or execute code. Indeed, some large, consumer-facing LLMs already incorporate these features. But Tool Use goes well beyond these examples.\\xa0If you prompt an online LLM-based chat system, ‚ÄúWhat is the best coffee maker according to reviewers?‚Äù, it might decide to carry out a web search and download one or more web pages to gain context. Early on, LLM developers realized that relying only on a pre-trained transformer to generate output tokens is limiting, and that giving an LLM a tool for web search lets it do much more. With such a tool, an LLM is either fine-tuned or prompted (perhaps with few-shot prompting) to generate a special string like {tool: web-search, query: \"coffee maker reviews\"} to request calling a search engine. (The exact format of the string depends on the implementation.) A post-processing step then looks for strings like these, calls the web search function with the relevant parameters when it finds one, and passes the result back to the LLM as additional input context for further processing.\\xa0Similarly, if you ask, ‚ÄúIf I invest $100 at compound 7% interest for 12 years, what do I have at the end?‚Äù, rather than trying to generate the answer directly using a transformer network ‚Äî which is unlikely to result in the right answer ‚Äî the LLM might use a code execution tool to run a Python command to compute 100 * (1+0.07)**12 to get the right answer. The LLM might generate a string like this: {tool: python-interpreter, code: \"100 * (1+0.07)**12\"}.\\xa0But Tool Use in agentic workflows now goes much further. Developers are using functions to search different sources (web, Wikipedia, arXiv, etc.), to interface with productivity tools (send email, read/write calendar entries, etc.), generate or interpret images, and much more. We can prompt an LLM using context that gives detailed descriptions of many functions. These descriptions might include a text description of what the function does plus details of what arguments the function expects. And we‚Äôd expect the LLM to automatically choose the right function to call to do a job.\\xa0Further, systems are being built in which the LLM has access to hundreds of tools. In such settings, there might be too many functions at your disposal to put all of them into the LLM context, so you might use heuristics to pick the most relevant subset to include in the LLM context at the current step of processing. This technique, which is described in the Gorilla paper cited below, is reminiscent of how, if there is too much text to include as context, retrieval augmented generation (RAG) systems offer heuristics for picking a subset of the text to include.\\xa0Early in the history of LLMs, before widespread availability of large multimodal models (LMMs) \\xa0like LLaVa, GPT-4V, and Gemini, LLMs could not process images directly, so a lot of work on Tool Use was carried out by the computer vision community. At that time, the only way for an LLM-based system to manipulate an image was by calling a function to, say, carry out object recognition or some other function on it. Since then, practices for Tool Use have exploded. GPT-4‚Äôs function calling capability, released in the middle of last year, was a significant step toward a general-purpose implementation. Since then, more and more LLMs are being developed to be similarly facile with Tool Use.\\xa0If you‚Äôre interested in learning more about Tool Use, I recommend:\\xa0‚ÄúGorilla: Large Language Model Connected with Massive APIs,‚Äù Patil et al. (2023)‚ÄúMM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action,‚Äù Yang et al. (2023)‚ÄúEfficient Tool Use with Chain-of-Abstraction Reasoning,‚Äù Gao et al. (2024)\\xa0 \\xa0Both Tool Use and Reflection, which I described in last week‚Äôs\\xa0letter, are design patterns that I can get to work fairly reliably on my applications ‚Äî both are capabilities well worth learning about. In future letters, I‚Äôll describe the Planning and Multi-agent collaboration design patterns. They allow AI agents to do much more but are less mature, less predictable ‚Äî albeit very exciting ‚Äî technologies.\\xa0Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp\\n'),\n",
       " Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 4: Planning', 'description': 'Planning is a key\\xa0agentic AI design pattern\\xa0in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute...', 'language': 'en'}, page_content='Agentic Design Patterns Part 4: Planning‚ú® New course! Enroll in Building Coding Agents with Tool ExecutionExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev x SF 26CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesMembershipStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 4, Planning Large language models can drive powerful agents to execute complex tasks if you ask them to plan the steps before they act.LettersTechnical InsightsPublishedApr 10, 2024Reading time3 min readShareDear friends,Planning is a key\\xa0agentic AI design pattern\\xa0in which we use a large language model (LLM) to autonomously decide on what sequence of steps to execute to accomplish a larger task. For example, if we ask an agent to do online research on a given topic, we might use an LLM to break down the objective into smaller subtasks, such as researching specific subtopics, synthesizing findings, and compiling a report.\\xa0Many people had a ‚ÄúChatGPT moment‚Äù shortly after ChatGPT was released, when they played with it and were surprised that it significantly exceeded their expectation of what AI can do. If you have not yet had a similar ‚ÄúAI Agentic moment,‚Äù I hope you will soon. I had one several months ago, when I presented a live demo of a research agent I had implemented that had access to various online search tools.\\xa0I had tested this agent multiple times privately, during which it consistently used a web search tool to gather information and wrote up a summary. During the live demo, though, the web search API unexpectedly returned with a rate limiting error. I thought my demo was about to fail publicly, and I dreaded what was to come next. To my surprise, the agent pivoted deftly to a Wikipedia search tool ‚Äî which I had forgotten I‚Äôd given it ‚Äî and completed the task using Wikipedia instead of web search.\\xa0This was an AI Agentic moment of surprise for me. I think many people who haven‚Äôt experienced such a moment yet will do so in the coming months. It‚Äôs a beautiful thing when you see an agent autonomously decide to do things in ways that you had not anticipated, and succeed as a result!Many tasks can‚Äôt be done in a single step or with a single tool invocation, but an agent can decide what steps to take. For example, to simplify an example from the HuggingGPT paper (cited below), if you want an agent to consider a picture of a boy and draw a picture of a girl in the same pose, the task might be decomposed into two distinct steps: (i) detect the pose in the picture of the boy and (ii) render a picture of a girl in the detected pose. An LLM might be fine-tuned or prompted (with few-shot prompting) to specify a plan by outputting a string like\\xa0\"{tool: pose-detection, input: image.jpg, output: temp1 } {tool: pose-to-image, input: temp1, output: final.jpg}\".\\xa0This structured output, which specifies two steps to take, then triggers software to invoke a pose detection tool followed by a pose-to-image tool to complete the task. (This example is for illustrative purposes only; HuggingGPT uses a different format.)\\xa0Admittedly, many agentic workflows do not need planning. For example, you might have an agent reflect on, and improve, its output a fixed number of times. In this case, the sequence of steps the agent takes is fixed and deterministic. But for complex tasks in which you aren‚Äôt able to specify a decomposition of the task into a set of steps ahead of time, Planning allows the agent to decide dynamically what steps to take.\\xa0On one hand, Planning is a very powerful capability; on the other, it leads to less predictable results. In my experience, while I can get the agentic design patterns of\\xa0Reflection\\xa0and\\xa0Tool Use\\xa0to work reliably and improve my applications‚Äô performance, Planning is a less mature technology, and I find it hard to predict in advance what it will do. But the field continues to evolve rapidly, and I\\'m confident that Planning abilities will improve quickly.\\xa0If you‚Äôre interested in learning more about Planning with LLMs, I recommend:‚ÄúChain-of-Thought Prompting Elicits Reasoning in Large Language Models,‚Äù Wei et al. (2022)‚ÄúHuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face,‚Äù Shen et al. (2023)‚ÄúUnderstanding the planning of LLM agents: A survey,‚Äù by Huang et al. (2024)Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"\\xa0Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp\\n'),\n",
       " Document(metadata={'source': 'https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io', 'title': 'Agentic Design Patterns Part 5, Multi-Agent Collaboration', 'description': 'Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I‚Äôve described in recent letters...', 'language': 'en'}, page_content='Agentic Design Patterns Part 5, Multi-Agent Collaboration‚ú® New course! Enroll in Building Coding Agents with Tool ExecutionExplore CoursesAI NewsletterThe BatchAndrew\\'s LetterData PointsML ResearchBlog‚ú® AI Dev x SF 26CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesMembershipStart LearningWeekly IssuesAndrew\\'s LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 5, Multi-Agent Collaboration Prompting an LLM to play different roles for different parts of a complex task summons a team of AI agents that can do the job more effectively.LettersTechnical InsightsPublishedApr 17, 2024Reading time3 min readShareDear friends,Multi-agent collaboration is the last of the four\\xa0key AI agentic design patterns\\xa0that I‚Äôve described in recent letters. Given a complex task like writing software, a multi-agent approach would break down the task into subtasks to be executed by different roles ‚Äî such as a software engineer, product manager, designer, QA (quality assurance) engineer, and so on ‚Äî and have different agents accomplish different subtasks.Different agents might be built by prompting one LLM (or, if you prefer, multiple LLMs) to carry out different tasks. For example, to build a software engineer agent, we might prompt the LLM: ‚ÄúYou are an expert in writing clear, efficient code. Write code to perform the task . . ..‚Äù\\xa0It might seem counterintuitive that, although we are making multiple calls to the same LLM, we apply the programming abstraction of using multiple agents. I‚Äôd like to offer a few reasons:It works! Many teams are getting good results with this method, and there‚Äôs nothing like results! Further, ablation studies (for example, in the AutoGen paper cited below) show that multiple agents give superior performance to a single agent.\\xa0Even though some LLMs today can accept very long input contexts (for instance, Gemini 1.5 Pro accepts 1 million tokens), their ability to truly understand long, complex inputs is mixed. An agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance. By telling it when it should play software engineer, we can also specify what is important in that role‚Äôs subtask. For example, the prompt above emphasized clear, efficient code as opposed to, say, scalable and highly secure code. By decomposing the overall task into subtasks, we can optimize the subtasks better.Perhaps most important, the multi-agent design pattern gives us, as developers, a framework for breaking down complex tasks into subtasks. When writing code to run on a single CPU, we often break our program up into different processes or threads. This is a useful abstraction that lets us decompose a task, like implementing a web browser, into subtasks that are easier to code. I find thinking through multi-agent roles to be a useful abstraction as well.In many companies, managers routinely decide what roles to hire, and then how to split complex projects ‚Äî like writing a large piece of software or preparing a research report ‚Äî into smaller tasks to assign to employees with different specialties. Using multiple agents is analogous. Each agent implements its own workflow, has its own memory (itself a rapidly evolving area in agentic technology: how can an agent remember enough of its past interactions to perform better on upcoming ones?), and may ask other agents for help. Agents can also engage in Planning and Tool Use. This results in a cacophony of LLM calls and message passing between agents that can result in very complex workflows.\\xa0While managing people is hard, it\\'s a sufficiently familiar idea that it gives us a mental framework for how to \"hire\" and assign tasks to our AI agents. Fortunately, the damage from mismanaging an AI agent is much lower than that from mismanaging humans!\\xa0Emerging frameworks like AutoGen, Crew AI, and LangGraph, provide rich ways to build multi-agent solutions to problems. If you\\'re interested in playing with a fun multi-agent system, also check out ChatDev, an open source implementation of a set of agents that run a virtual software company. I encourage you to check out their\\xa0GitHub repo\\xa0and perhaps clone the repo and run the system yourself. While it may not always produce what you want, you might be amazed at how well it does.\\xa0Like the design pattern of\\xa0Planning, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of\\xa0Reflection\\xa0and\\xa0Tool Use\\xa0are more reliable. I hope you enjoy playing with these agentic design patterns and that they produce amazing results for you!\\xa0If you\\'re interested in learning more, I recommend:\\xa0‚ÄúCommunicative Agents for Software Development,‚Äù Qian et al. (2023) (the ChatDev paper)‚ÄúAutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,‚Äù Wu et al. (2023)\\xa0‚ÄúMetaGPT: Meta Programming for a Multi-Agent Collaborative Framework,‚Äù Hong et al. (2023)Keep learning!AndrewRead \"Agentic Design Patterns Part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance\"Read \"Agentic Design Patterns Part 2: Reflection\"\\xa0Read \"Agentic Design Patterns Part 3: Tool Use\"Read \"Agentic Design Patterns Part 4:\\xa0Planning\" ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp\\n')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96a6112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks : 44\n",
      "(\"Example chunk : page_content='Four AI Agent Strategies That Improve GPT-4 \"\n",
      " 'and GPT-3.5 Performance‚ú® New course! Enroll in Building Coding Agents with '\n",
      " \"Tool ExecutionExplore CoursesAI NewsletterThe BatchAndrew's LetterData \"\n",
      " 'PointsML ResearchBlog‚ú® AI Dev x SF '\n",
      " '26CommunityForumEventsAmbassadorsAmbassador '\n",
      " \"SpotlightResourcesMembershipStart LearningWeekly IssuesAndrew's LettersData \"\n",
      " 'PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe '\n",
      " 'BatchLettersArticleAgentic Design Patterns Part 1 Four AI agent strategies '\n",
      " 'that improve GPT-4 and GPT-3.5 performanceLettersTechnical '\n",
      " \"InsightsPublishedMar 20, 2024Reading time2 min' metadata={'source': \"\n",
      " \"'https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io', \"\n",
      " \"'title': 'Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 \"\n",
      " \"Performance', 'description': 'I think AI agent workflows will drive massive \"\n",
      " 'AI progress this year ‚Äî perhaps even more than the next generation of '\n",
      " \"foundation models. This is an important...', 'language': 'en'}\")\n"
     ]
    }
   ],
   "source": [
    "# use RecursiveTextSplitter for efficient chunking\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)\n",
    "doc_chunks = text_splitter.split_documents(docs_list)\n",
    "\n",
    "print(f\"Total chunks : {len(doc_chunks)}\")\n",
    "pprint(f\"Example chunk : {doc_chunks[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41058a97",
   "metadata": {},
   "source": [
    "## Creating a VectorDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded3607",
   "metadata": {},
   "source": [
    "This time we'll use ChromDB (locally) with persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53b8fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"reliable_rag\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"../persistent_vectordb/chroma_langchain_db1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb8d41c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ada2fdcd-14e2-4204-8979-c64826de3cfe',\n",
       " '93ad62a6-57a1-427d-93b4-03fbc504251a',\n",
       " '5d0c709b-3ecd-4650-b2ea-b11d6f046b03',\n",
       " 'd38b5dad-3951-48b5-9232-08732261093c',\n",
       " '46a83631-36ae-4624-ac9c-97b9ec63fba6',\n",
       " '9aa86f82-76e2-478b-b016-83a9cf4edd83',\n",
       " 'd0784f62-bdaf-4c12-ae49-3001a9e5eedd',\n",
       " '2ca788cd-3239-4c06-a5c1-fb81b8a344ac',\n",
       " 'e9f305ab-a51f-4871-9ade-67def2c78ce7',\n",
       " 'caabe9b5-23ab-46b7-862b-b86c4f15c4db',\n",
       " 'c39af50d-e94a-4dfa-8f4f-12f31dd5ace5',\n",
       " 'b0c4080c-5369-4fde-89b6-630d458ebf15',\n",
       " 'b4e749f3-b370-4f98-ac95-6d301855d29f',\n",
       " '495e8702-c89a-4d91-8826-f99503483b18',\n",
       " 'd4301986-987f-444c-984b-0a4567f78d5a',\n",
       " '4bb3fe33-44c0-4fc4-9e1c-207cea6bbf20',\n",
       " 'e22c4bb4-b7e6-45b3-bbac-9267fad8b748',\n",
       " '1badaa58-2754-47fb-a530-30704ce03929',\n",
       " '561578ec-4a9e-4ba3-a1d8-7cb664fd272d',\n",
       " '71f69bf0-a372-4ec2-9b74-fd5168bcf946',\n",
       " 'b66aaa4b-69ee-4767-a4f9-28044d2ac9b8',\n",
       " '1576eba7-f918-4617-91be-662fc36c1680',\n",
       " '3f70d674-c35f-4e02-86c0-80bbab2117b8',\n",
       " 'a62c3db7-8a80-4238-a335-5ae73f0397c8',\n",
       " 'a9ca5b6d-0edd-4a7e-ae88-3b2133987e2f',\n",
       " 'cb91805b-365b-426c-abaf-c470cbb5580a',\n",
       " '199e3f27-47fe-4ee0-ac8a-195eb2facc37',\n",
       " 'b7869fa1-6b14-4275-a658-19a929c14e8b',\n",
       " '1f49b211-5694-403b-ac1f-5bab6a644ea3',\n",
       " '65915fb4-aea9-4072-bbd8-44046377ea6a',\n",
       " '0be33bb3-8af2-420f-ba7e-b3c8db90ff0a',\n",
       " 'edcf3163-5d41-4f54-8574-2650f1640acc',\n",
       " '0b0e9e1b-0917-42d4-8fc8-5e7c1d9d89c8',\n",
       " '9830f41a-bb06-4bee-b107-5227895d2e6f',\n",
       " '78c3e6db-7771-4076-a0cc-5823df1877a5',\n",
       " '5aa786e2-8f7a-4aec-bbdb-749391192a99',\n",
       " '4112c7ee-0c98-4a45-bddd-09254835e901',\n",
       " '3a9c55be-4dcb-4604-8dcc-06b612e0af95',\n",
       " '5dd8a858-dfaa-4d14-9f76-0a8fd0d41c7d',\n",
       " 'efba9037-805f-474a-ad99-b4f20372d01f',\n",
       " 'e9140dd1-89d2-4439-a38d-ab336801bac5',\n",
       " '815d7d9b-1a54-47c4-a5dd-c7b2e2fc61c8',\n",
       " '5f6c7b9c-e5aa-4637-9a76-839544db8e88',\n",
       " '4dfb3b59-607e-4724-a5a7-6a6138c810bd']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding chunks to our DB\n",
    "vector_store.add_documents(documents=doc_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20b490",
   "metadata": {},
   "source": [
    "## üî• What is MMR?\n",
    "\n",
    "**MMR (Maximal Marginal Relevance)** is a re-ranking strategy used in retrieval systems to pick documents that are:\n",
    "\n",
    "- **Highly relevant to the query** (Query Relevance)\n",
    "- **Not redundant with each other** (Document Diversity)\n",
    "\n",
    "\n",
    "\n",
    "This ensures the final retrieved set is *diverse* and avoids repetitive or overlapping chunks.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Why MMR is useful\n",
    "\n",
    "Normal vector search often returns many chunks that are very similar to each other.  \n",
    "MMR fixes this by balancing:\n",
    "\n",
    "- **How close a chunk is to the query** (Relevance term = Information Gain)\n",
    "- **How different it is from already selected chunks** (Diversity term = Redundancy Penalty)\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ How MMR works (simple view)\n",
    "\n",
    "1. Retrieve **`fetch_k`** top similar documents using vector similarity.\n",
    "2. Apply MMR re-ranking to select the best **`k`** documents that maximize:\n",
    "   - relevance to the query  \n",
    "   - diversity among selected documents  \n",
    "\n",
    "---\n",
    "\n",
    "### üîπ In simple words\n",
    "\n",
    "MMR picks:\n",
    "1. The most relevant document.\n",
    "2. The next document that adds the most **new information** (not repetitive).\n",
    "3. Continues until it selects **k** diverse + relevant chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87a2c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e28c56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc : 1\n",
      "Content : Agentic Design Patterns Part 3: Tool Use‚ú® New course! Enroll in Building Coding Agents with Tool ExecutionExplore CoursesAI NewsletterThe BatchAndrew's LetterData PointsML ResearchBlog‚ú® AI Dev x SF 26CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesMembershipStart LearningWeekly IssuesAndrew's LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 3, Tool Use How large language models can act as agents by taking advantage of external tools for search, code execution, productivity, ad\n",
      "-----------------------------------------------------------------------------------------\n",
      "Doc : 2\n",
      "Content : performance\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# sample testing of retriever\n",
    "sample_context = retriever.invoke(\"what are the differnt kind of agentic design patterns?\")\n",
    "\n",
    "for i, doc in enumerate(sample_context):\n",
    "    print(f\"Doc : {i+1}\")\n",
    "    print(f\"Content : {doc.page_content}\")\n",
    "    print(\"-\"*89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6dc70c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e99304",
   "metadata": {},
   "source": [
    "### Checking Document Relevancy (Query <-> Retrieved Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "068b30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated\n",
    "\n",
    "# data validation class (LLM output)\n",
    "class ClassifyContext(BaseModel):\n",
    "    \"\"\"\n",
    "    When context is retrived for a query then relevancy value (True or False) is validated by this class.\n",
    "    \"\"\"\n",
    "    value: Annotated[bool, Field(..., description=\"'True' or 'False', whether context is relevant to query\")]\n",
    "\n",
    "# configure our llm to produce this structured output\n",
    "structured_llm_grader = llm.with_structured_output(ClassifyContext)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"You are a grader assessing relevance of a retrieved  document : {context} to a user question : {query}. \" \\\n",
    "    \"If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \" \\\n",
    "    \"It does not need to be a stringent test. The goal is to filter out erroneous retrievals. Give a boolean value 'True' or 'False' score to indicate whether the document is relevant to the question.\"\n",
    ")\n",
    "\n",
    "relevancy_check_chain = prompt | structured_llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d31f50ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : what are the differnt kind of agentic design patterns?\n",
      "-----------------------------------------------------------------------------------------\n",
      "Context : Agentic Design Patterns Part 3: Tool Use‚ú® New course! Enroll in Building Coding Agents with Tool ExecutionExplore CoursesAI NewsletterThe BatchAndrew's LetterData PointsML ResearchBlog‚ú® AI Dev x SF 26CommunityForumEventsAmbassadorsAmbassador SpotlightResourcesMembershipStart LearningWeekly IssuesAndrew's LettersData PointsML ResearchBusinessScienceCultureHardwareAI CareersAboutSubscribeThe BatchLettersArticleAgentic Design Patterns Part 3, Tool Use How large language models can act as agents by taking advantage of external tools for search, code execution, productivity, ad\n",
      "Response : value=True\n",
      "-----------------------------------------------------------------------------------------\n",
      "Context : performance\"Read \"Agentic Design Patterns Part 3, Tool Use\"Read \"Agentic Design Patterns Part 4: Planning\"Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\"ShareSubscribe to The BatchStay updated with weekly AI News and Insights delivered to your inboxCoursesThe BatchCommunityCareersAboutContactHelp\n",
      "Response : value=True\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# checking relevancy of retrieved docs \n",
    "query = \"what are the differnt kind of agentic design patterns?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"Query : {query}\")\n",
    "print(\"-\"*89)\n",
    "\n",
    "# we'll store context that is truely related to query side by side\n",
    "true_context = \"\"\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"Context : {doc.page_content}\")\n",
    "    llm_score = relevancy_check_chain.invoke({'query' : query, 'context' : doc.page_content})\n",
    "    print(f\"Response : {llm_score}\")\n",
    "    print(\"-\"*89)\n",
    "    # store true context\n",
    "    if llm_score.value == True:\n",
    "        true_context += doc.page_content\n",
    "        true_context += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "302016fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create a function that first verfies whether retrieved context is really helful to answer the query \n",
    "import time\n",
    "\n",
    "def get_and_validate_retrieved_context(retriever, query):\n",
    "    # get the context\n",
    "    start = time.time()\n",
    "    retrieved_context = retriever.invoke(query)\n",
    "    mid = time.time()\n",
    "    print(f\"Time take to retrieve context : {mid-start} sec\")\n",
    "    print(\"-\"*89)\n",
    "\n",
    "    # true_context\n",
    "    true_context_docs = []\n",
    "\n",
    "    for doc in retrieved_docs:\n",
    "        is_relevant = relevancy_check_chain.invoke({'query' : query, 'context' : doc.page_content})\n",
    "        if is_relevant.value == True:\n",
    "            true_context_docs.append(doc.page_content)\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Time take to validate retrieved context : {end-mid} sec\")\n",
    "    print(\"-\"*89)\n",
    "        \n",
    "    return true_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5e31ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM to generate response from query and context\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "prompt_for_response = PromptTemplate.from_template(\n",
    "    \"You are a helpful assistant. Look at the user query : <query>{query}</query> and \" \\\n",
    "    \"try to answer it in 2-3 lines using context : <context>{context}</context> \" \\\n",
    "    \"If no context is provided just respond with No relevant docs found.\"\n",
    ")\n",
    "\n",
    "response_chain = prompt_for_response | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ca1d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : what are the differnt kind of agentic design patterns?\n",
      "-----------------------------------------------------------------------------------------\n",
      "Time take to retrieve context : 0.4318091869354248 sec\n",
      "-----------------------------------------------------------------------------------------\n",
      "Time take to validate retrieved context : 21.599080801010132 sec\n",
      "-----------------------------------------------------------------------------------------\n",
      "Response : Based on the Agentic Design Patterns, here are some of the main types:\n",
      "\n",
      "1. Agent-based systems: These are systems that use multiple autonomous agents to achieve a common goal.\n",
      "2. Multi-agent systems: These are systems that consist of multiple agents that interact with each other to achieve a common goal.\n",
      "3. Autonomous intelligent agents: These are agents that have the ability to make decisions and take actions without human intervention.\n",
      "\n",
      "These patterns are used in various fields such as artificial intelligence, robotics, and computer science to create complex systems that can adapt and respond to changing environments.\n"
     ]
    }
   ],
   "source": [
    "# let try this flow \n",
    "if __name__ == \"__main__\":\n",
    "    query = \"what are the differnt kind of agentic design patterns?\"\n",
    "    print(f\"Query : {query}\")\n",
    "    print(\"-\"*89)\n",
    "    context_list = get_and_validate_retrieved_context(retriever, query)\n",
    "    context = \"\"\n",
    "    for doc in context_list:\n",
    "        context += doc \n",
    "        context += \"\\n\\n\"\n",
    "    response = response_chain.invoke({'context' : context, 'query' : query})\n",
    "    print(f\"Response : {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df6135",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138e8b0",
   "metadata": {},
   "source": [
    "### Now we need to do hallucination checks (Generated answer <-> context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf71ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated\n",
    "\n",
    "# LLM response validation\n",
    "class HallucinationValidator(BaseModel):\n",
    "    \"\"\"\n",
    "    If generated response contains content that is not present in context then it flags it by 'False' otherwise 'True'\n",
    "    \"\"\"\n",
    "    valid: Annotated[bool, Field(..., description=\"'True' or 'False' on basis of validation whether generated response.\")]\n",
    "\n",
    "# configure our llm to produce this structured output\n",
    "structured_llm_halluciantion_checker = llm.with_structured_output(HallucinationValidator)\n",
    "\n",
    "answer_hallucination_check_prompt = PromptTemplate.from_template(\n",
    "    \"You are provided with a generated response : {generated_response} and some context : {context}. You need to check whether generated_response if a subset of context and not contains any irrelevant content. If generate_respose is hallucinated return 'True' otherwise 'False'.\"\n",
    ")\n",
    "\n",
    "hallucination_checking_chain = answer_hallucination_check_prompt | structured_llm_halluciantion_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1070050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : what are the differnt kind of agentic design patterns?\n",
      "-----------------------------------------------------------------------------------------\n",
      "Time take to retrieve context : 0.4074101448059082 sec\n",
      "-----------------------------------------------------------------------------------------\n",
      "Time take to validate retrieved context : 18.18198299407959 sec\n",
      "-----------------------------------------------------------------------------------------\n",
      "Time taken to generate response : 32.927732944488525 sec.\n",
      "-----------------------------------------------------------------------------------------\n",
      "Time take to check hallucination : 19.928250074386597 sec\n",
      "-----------------------------------------------------------------------------------------\n",
      "Answer is Hallucinated? : False\n",
      "-----------------------------------------------------------------------------------------\n",
      "Response : Based on the Agentic Design Patterns, here are some of the main types:\n",
      "\n",
      "1. Agent-based systems: These are systems that use multiple autonomous agents to achieve a common goal.\n",
      "2. Multi-agent systems: These are systems that consist of multiple agents that interact with each other to achieve a common goal.\n",
      "3. Autonomous intelligent agents: These are agents that have the ability to make decisions and take actions without human intervention.\n",
      "\n",
      "These patterns are used in various fields such as artificial intelligence, robotics, and computer science to create complex systems that can adapt and respond to changing environments.\n"
     ]
    }
   ],
   "source": [
    "# let try this flow \n",
    "if __name__ == \"__main__\":\n",
    "    query = \"what are the differnt kind of agentic design patterns?\"\n",
    "    print(f\"Query : {query}\")\n",
    "    print(\"-\"*89)\n",
    "    context_list = get_and_validate_retrieved_context(retriever, query)\n",
    "    context = \"\"\n",
    "    for doc in context_list:\n",
    "        context += doc \n",
    "        context += \"\\n\\n\"\n",
    "    start = time.time()\n",
    "    response = response_chain.invoke({'context' : context, 'query' : query})\n",
    "    print(f\"Time taken to generate response : {time.time() - start} sec.\")\n",
    "    print(\"-\"*89)\n",
    "\n",
    "    # check for hallucinations\n",
    "    start = time.time()\n",
    "    hallucination_validator = hallucination_checking_chain.invoke({'generated_response' : response.content, 'context' : context})\n",
    "    print(f\"Time take to check hallucination : {time.time() - start} sec\")\n",
    "    print(\"-\"*89)\n",
    "    print(f\"Answer is Hallucinated? : {hallucination_validator.valid}\")\n",
    "    print(\"-\"*89)\n",
    "    print(f\"Response : {response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c3e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
